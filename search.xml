<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[软件测试的艺术第三章总结]]></title>
    <url>%2F2019%2F01%2F26%2F%E8%BD%AF%E4%BB%B6%E6%B5%8B%E8%AF%95%E7%9A%84%E8%89%BA%E6%9C%AF%E7%AC%AC%E4%B8%89%E7%AB%A0%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[软件测试的艺术第二章总结]]></title>
    <url>%2F2019%2F01%2F26%2F%E8%BD%AF%E4%BB%B6%E6%B5%8B%E8%AF%95%E7%9A%84%E8%89%BA%E6%9C%AF%E7%AC%AC%E4%BA%8C%E7%AB%A0%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[软件测试的定义 测试是为发现错误而执行程序的过程 软件测试的心理学 通过测试来增加程序的价值，是指测试提高了程序的可靠性或质量。提高了程序的可靠性，是指找出并最终修改了程序的错误。因此不要只是为了证明程序能够正确运行而去测试程序；相反，应该一开始就假设程序中隐藏着错误（这种假设对于几乎所有的程序都成立），然后测试程序，发现尽可能多的错误如果我们的目的是证明程序中不存在错误，那就会在潜意识中倾向于实现这个目标，也就是说，我们会倾向于选择可能较少导致程序失效的测试数据。另一方面，如果我们的目标在于证明程序中存在错误，我们设计的测试数据就有可能更多地发现间题把程序当成病人，要找出病因 软件测试的艺术 测试用例中一个必需部分是对预期输出或结果的定义 程序员应当避免测试自己编写的程序 编写软件的组织不应当测试自己编写的软件 应当彻底检查每个测试的执行结果 测试用例的编写不仅应当根据有效和预期的输入情况，而且也应当根据无效和未预料到的输入情况 检查程序是否“未做其应该做的”仅是测试的一半，测试的另一半是检查程序是否“做了其不应该做的” 应避免测试用例用后即弃，除非软件本身就是一个一次性的软件 计划测试工作时不应默许假定不会发现错误 程序某部分存在更多错误的可能性，与该部分已发现错误的数目成正比 软件测试是一项极富创造性、极具智力挑战性的工作 总结 软件测试是为发现错误而执行程序的过程 一个好的测试用例具有较高的发现某个尚未发现的错误的可能性 一个成功的测试用例能够发现某个尚未发现的错误]]></content>
      <categories>
        <category>软件测试</category>
      </categories>
      <tags>
        <tag>测试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[软件测试的艺术中的小测验]]></title>
    <url>%2F2019%2F01%2F25%2F%E8%BD%AF%E4%BB%B6%E6%B5%8B%E8%AF%95%E7%9A%84%E8%89%BA%E6%9C%AF%E4%B8%AD%E7%9A%84%E5%B0%8F%E6%B5%8B%E9%AA%8C%2F</url>
    <content type="text"><![CDATA[测试的程序这个程序从一个输入对话框中读取三个整数值。这三个整数值代表了三角形三边的长度。程序显示提示信息，指出该三角形究竟是不规则三角形、等腰三角形还是等边三角形。 分析对输入条件可以划分这么几个规则： 边长是否为整数 是否输入了三边 三边是否符合三角形规则 边长是否大于0 划分等价类 编写测试用例有效等价类 三边长 预期输出 1,1,1 等边三角形 2,2,3 等腰三角形 2,3,2 等腰三角形 3,2,2 等腰三角形 4,5,6 不规则三角形 4,6,5 不规则三角形 6,5,4 不规则三角形 无效等价类 三边长 预期输出 1.5,1.5,1.5 请输入整数 a,b,c 请输入整数 不输入 请输入完整的三边长 1,null,null 请输入完整的三边长 1,2,null 请输入完整的三边长 2,2,6 三边不符合三角形规则 3,3,6 三边不符合三角形规则 -1,-1,-1 请输入大于0的三边长 0,0,0 请输入大于0的三边长]]></content>
      <categories>
        <category>软件测试</category>
      </categories>
      <tags>
        <tag>测试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于webdriver]]></title>
    <url>%2F2019%2F01%2F24%2F%E5%85%B3%E4%BA%8Ewebdriver%2F</url>
    <content type="text"><![CDATA[webdriver协议 webdriver协议是一套json格式的规范，本身是基于http协议的这个协议规定了每个操作对应的数据格式，webdriver作为一个服务端，需要实现协议中的每一个操作作为客户端的库文件需要封装好给用户使用的api，每个api对应着协议中不同的数据格式，这些数据封装在http中的body中，数据格式内容和具体的操作一一对应selenium中的webdriver就是浏览器驱动，比如ChromeDriver等，驱动实现了webdriver协议appium中的webdriver是appium server通俗地说：由于客户端脚本(java, python, ruby)不能直接与浏览器/手机通信，这时候可以把webdriver server当做一个翻译器，它可以把客户端代码翻译成浏览器/手机可以识别的代码(比如js)，客户端通过http请求向webdriver server发送restful的请求，webdriver server翻译成浏览器/手机懂得脚本传给浏览器/手机，浏览器/手机把执行的结果返回给webdriver server,webdriver server把返回的结果做了一些封装(JSON Wire protocol)，然后返回给客户端脚本，客户端根据返回值就能判断对浏览器/手机的操作是否执行成功协议就像是一个抽象类，规定了方法，以及触发方法所需要的数据格式和内容，但是没有具体实现；服务端需要具体去实现这些方法；客户端则需要按照协议规定的数据格式和内容去封装提供给用户的api selenium中的WebDriver类 selenium作为一个客户端，提供给用户的接口基本都在selenium/webdriver/remote/webdriver.py中的WebDriver类中实现这个类是selenium中所有关于浏览器driver类的基类截取Chrome webdriver类中初始化的一段代码：1234567891011try: RemoteWebDriver.__init__( self, command_executor=ChromeRemoteConnection( remote_server_addr=self.service.service_url, keep_alive=keep_alive), desired_capabilities=desired_capabilities)except Exception: self.quit() raiseself._is_remote = False 可以看到调用了基类的初始化方法，来连接到webdriver server，在此之前会寻找浏览器驱动，并自动启动服务：123456self.service = Service( executable_path, # 默认为chromedriver port=port, service_args=service_args, log_path=service_log_path)self.service.start() #启动server 之后，脚本调用对应的api，就会向这个server发送符合webdriver协议规范的http请求，server接收请求来操作浏览器 appium中的WebDriver类 appium中的WebDriver继承自很多类，功能更加丰富，当然它也继承了selenium中的webdriver基类12345678910111213141516class WebDriver( ActionHelpers, Activities, Applications, Clipboard, Context, DeviceTime, HardwareActions, ImagesComparison, IME, Keyboard, Location, Network, RemoteFS, ScreenRecord): 在初始化中，command_executor参数填写的是appium server的地址+端口号，这个appium server我们在运行脚本前需要手动启动之后脚本调用对应的api，就会向这个appium server发送符合webdriver协议规范的http请求，appium server接收请求来操作手机 总结webdriver中的三个角色 测试脚本——作为客户端 浏览器驱动/appium server——作为服务端 浏览器/手机——作为服务端操作的对象 客户端包的作用 屏蔽有关协议的内容，让用户不必关心这些细节，只需使用提供给用户的api即可完成相应的操作]]></content>
      <categories>
        <category>软件测试</category>
      </categories>
      <tags>
        <tag>测试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[web测试点总结]]></title>
    <url>%2F2019%2F01%2F23%2Fweb%E6%B5%8B%E8%AF%95%E7%82%B9%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[输入框 字符型输入框 字符型输入框：英文全角、英文半角、数字、空或者空格、特殊字符“~！@#￥%……&amp;*？[]{}”特别要注意单引号和&amp;符号。禁止直接输入特殊字符时，使用“粘贴、拷贝”功能尝试输入 长度检查：最小长度、最大长度、最小长度-1、最大长度+1、输入超多的字符比如把整个文章拷贝过去 空格检查：输入的字符间有空格、字符前有空格、字符后有空格、字符前后有空格 多行文本框输入：允许回车换行、保存后再显示能够保存输入的格式、仅输入回车换行，检查能否正确保存（若能，检查保存结果，若不能，查看是否有正常提示） 安全性检查：输入特殊字符串1（null,NULL, ,javascript,&lt;script&gt;,&lt;/script&gt;,&lt;title&gt;,&lt;html&gt;,&lt;td&gt;）、输入脚本函数(&lt;script&gt;alert(&quot;abc&quot;)&lt;/script&gt;)、doucment.write(&quot;abc&quot;)、&lt;b&gt;hello&lt;/b&gt;） 数值型输入框 边界值：最大值、最小值、最大值+1、最小值-1 位数：最小位数、最大位数、最小位数-1、最大位数+1、输入超长值、输入整数 异常值、特殊字符：输入空白（NULL）、空格或”~!@#$%^&amp;*等可能导致系统错误的字符、禁止直接输入特殊字符时，尝试使用粘贴拷贝查看是否能正常提交、word中的特殊功能，通过剪贴板拷贝到输入框，分页符，分节符类似公式的上下标等、数值的特殊符号如∑，㏒，㏑，∏，+，-等、输入负整数、负小数、分数、输入字母或汉字、小数（小数前0点舍去的情况，多个小数点的情况）、首位为0的数字如01、02、科学计数法是否支持1.0E2、全角数字与半角数字、数字与字母混合、16进制，8进制数值、货币型输入（允许小数点后面几位） 安全性检查：不能直接输入就copy 日期型输入框 合法性检查：(输入0日、1日、32日)、月输入[1、3、5、7、8、10、12]、日输入[31]、月输入[4、6、9、11]、日输入[30][31]、输入非闰年，月输入[2]，日期输入[28、29]、输入闰年，月输入[2]、日期输入[29、30]、月输入[0、1、12、13] 异常值、特殊字符：输入空白或NULL、输入~！@#￥%……&amp;*（）{}[]等可能导致系统错误的字符 安全性检查：不能直接输入，就copy，是否数据检验出错 信息重复在一些需要命名,且名字应该唯一的信息输入重复的名字或ID,看系统有没有处理,是否会报错,重名包括是否区分大小写,以及在输入内容的前后输入空格,系统是否作出正确处理 搜索功能 功能实现 果支持模糊查询，搜索名称中任意一个字符是否能搜索到 比较长的名称是否能查到 输入系统中不存在与之匹配的条件 用户进行查询操作时，一般情况是不进行查询条件的清空，除非需求特殊说明 组合测试 不同查询条件之间来回选择，是否出现页面错误（单选框和多选框最容易出错） 测试多个查询条件时，要注意查询条件的组合测试，可能不同组合的测试会报错 添加、修改功能 特殊键 是否支持Tab键 是否支持回车键 提示信息不符合要求的地方是否有错误提示 唯一性字段唯一的，是否可以重复添加，添加后是否能修改为已存在的字段（字段包括区分大小写以及在输入的内容前后输入空格，保存后，数据是否真的插入到数据库中，注意保存后数据的正确性） 数据 正确性 对编辑页的每个编辑项进行修改，点击保存，是否可以保存成功，检查想关联的数据是否得到更新。 进行必填项检查（即是否给出提示以及提示后是否依然把数据存到数据库中；是否提示后出现页码错乱等） 是否能够连续添加（针对特殊情况） 在编辑的时候，注意编辑项的长度限制，有时在添加的时候有，在编辑的时候却没有（注意要添加和修改规则是否一致） 对于有图片上传功能的编辑框，若不上传图片，查看编辑页面时是否显示有默认的图片，若上传图片，查看是否显示为上传图片 修改后增加数据后，特别要注意查询页面的数据是否及时更新，特别是在首页时要注意数据的更新 提交数据时，连续多次点击，查看系统会不会连续增加几条相同的数据或报错 若结果列表中没有记录或者没选择某条记录，点击修改按钮，系统是否会抛异常 删除功能 特殊键 是否支持delete键 是否支持backup键 提示信息 不选择任何信息，直接点击删除按钮，是否有提示 删除某条信息时，应该有确认提示 数据实现 是否能连续删除多个产品 当只有一条数据时，是否可以删除成功 删除一条数据后，是否可以添加相同的数据 如系统支持批量删除，注意删除的信息是否正确 如有全选，注意是否把所有的数据删除 删除数据时，要注意相应查询页面的数据是否及时更新 如删除的数据与其他业务数据关联，要注意其关联性（如删除部门信息时，部门下游员工，则应该给出提示） 如果结果列表中没有记录或没有选择任何一条记录，点击删除按钮系统会报错 注册、登陆模块 注册功能 注册时，设置密码为特殊字符，检查登录时是否会报错 注册成功后，页面应该以登陆状态跳转到首页或指定页面 在注册信息中删除已输入的信息，检查是否可以注册成功。 登陆功能 输入正确的用户名和正确的密码 输入正确的用户名和错误的密码 输入错误的用户名和正确的密码 输入错误的用户名和错误的密码 不输入用户名和密码（均为空格） 只输入用户名，密码为空 用户名为空，只输入密码 输入正确的用户名和密码，但是不区分大小写 用户名和密码包括特殊字符 用户名和密码输入超长值 已删除的用户名和密码 登录时，当页面刷新或重新输入数据时，验证码是否更新 上传功能 文件类型正确、大小合适 文件类型正确，大小不合适 文件类型错误，大小合适 文件类型和大小都合适，上传一个正在使用中的图片 文件类型大小都合适，手动输入存在的图片地址来上传 文件类型和大小都合适，输入不存在的图片地址来上传 文件类型和大小都合适，输入图片名称来上传 不选择文件直接点击上传，查看是否给出提示 连续多次选择不同的文件，查看是否上传最后一次选择的文件 查询结果列表 列表、列宽是否合理 列表数据太宽有没有提供横向滚动 列表的列名有没有与内容对应 列表的每列的列名是否描述的清晰 列表是否把不必要的列都显示出来 点击某列进行排序，是否会报错（点击查看每一页的排序是否正确） 双击或单击某列信息，是否会报错 返回键检查 一条已经成功提交的记录，返回后再提交，是否做了处理 检查多次使用返回键的情况，在有返回键的地方，返回到原来的页面多次，查看是否会出错 回车键检查在输入结果后，直接按回车键，看系统如何处理，是否会报错 刷新键检查在Web系统中，使用刷新键，看系统如何处理，是否会报错 直接URL链接检查在Web系统中，在地址栏直接输入各个功能页面的URL地址，看系统如何处理，是否能够直接链接查看（匿名查看），是否有权限控制，是否直接执行，并返回相应结果页 界面和易用性测试 风格、样式、颜色是否协调 界面布局是否整齐、协调（保证全部显示出来的，尽量不要使用滚动条 界面操作、标题描述是否恰当（描述有歧义、注意是否有错别字） 操作是否符合人们的常规习惯（有没有把相似的功能的控件放在一起，方便操作） 提示界面是否符合规范（不应该显示英文的cancel、ok，应该显示中文的确定等） 界面中各个控件是否对齐 日期控件是否可编辑 日期控件的长度是否合理，以修改时可以把时间全部显示出来为准 查询结果列表列宽是否合理、标签描述是否合理 查询结果列表太宽没有横向滚动提示 对于信息比较长的文本，文本框有没有提供自动竖直滚动条 数据录入控件是否方便 有没有支持Tab键，键的顺序要有条理，不乱跳 有没有提供相关的热键 控件的提示语描述是否正确 模块调用是否统一，相同的模块是否调用同一个界面 用滚动条移动页面时，页面的控件是否显示正常 日期的正确格式应该是XXXX-XX-XX或XXXX-XX-XX XX:XX:XX 页面是否有多余按钮或标签 窗口标题或图标是否与菜单栏的统一 窗口的最大化、最小化是否能正确切换 对于正常的功能，用户可以不必阅读用户手册就能使用 执行风险操作时，有确认、删除等提示吗 操作顺序是否合理 正确性检查：检查页面上的form, button, table, header, footer,提示信息，还有其他文字拼写，句子的语法等是否正确。 系统应该在用户执行错误的操作之前提出警告，提示信息. 页面分辨率检查，在各种分辨率浏览系统检查系统界面友好性。 合理性检查：做delete, update, add, cancel, back等操作后，查看信息回到的页面是否合理。 检查本地化是否通过：英文版不应该有中文信息，英文翻译准确，专业。 兼容性测试兼容性测试不只是指界面在不同操作系统或浏览器下的兼容，有些功能方面的测试，也要考虑到兼容性，包括操作系统兼容和应用软件兼容，可能还包括硬件兼容比如涉及到ajax、jquery、javascript等技术的，都要考虑到不同浏览器下的兼容性问题。 链接测试 导航测试导航描述了用户在一个页面内操作的方式，在不同的用户接口控制之间，例如按钮、对话框、列表和窗口等；或在不同的连接页面之间。通过考虑下列问题，可以决定一个Web应用系统是否易于导航：导航是否直观？Web系统的主要部分是否可通过主页存取？Web系统是否需要站点地图、搜索引擎或其他的导航帮助？在一个页面上放太多的信息往往起到与预期相反的效果。Web应用系统的用户趋向于目的驱动，很快地扫描一个Web应用系统，看是否有满足自己需要的信息，如果没有，就会很快地离开。很少有用户愿意花时间去熟悉Web应用系统的结构，因此，Web应用系统导航帮助要尽可能地准确。导航的另一个重要方面是Web应用系统的页面结构、导航、菜单、连接的风格是否一致。确保用户凭直觉就知道Web应用系统里面是否还有内容，内容在什么地方。Web应用系统的层次一旦决定，就要着手测试用户导航功能，让最终用户参与这种测试，效果将更加明显。 图形测试在Web应用系统中，适当的图片和动画既能起到广告宣传的作用，又能起到美化页面的功能。一个Web应用系统的图形可以包括图片、动画、边框、颜色、字体、背景、按钮等。图形测试的内容有： 要确保图形有明确的用途，图片或动画不要胡乱地堆在一起，以免浪费传输时间。Web应用系统的图片尺寸要尽量地小，并且要能清楚地说明某件事情，一般都链接到某个具体的页面。 验证所有页面字体的风格是否一致。 背景颜色应该与字体颜色和前景颜色相搭配。 图片的大小和质量也是一个很重要的因素，一般采用JPG或GIF压缩，最好能使图片的大小减小到30k以下 最后，需要验证的是文字回绕是否正确。如果说明文字指向右边的图片，应该确保该图片出现在右边。不要因为使用图片而使窗口和段落排列古怪或者出现孤行。通常来说，使用少许或尽量不使用背景是个不错的选择。如果您想用背景，那么最好使用单色的，和导航条一起放在页面的左边。另外，图案和图片可能会转移用户的注意力。 业务流程测试业务流程，一般会涉及到多个模块的数据，所以在对业务流程测试时，首先要保证单个模块功能的正确性，其次就要对各个模块间传递的数据进行测试，这往往是容易出现问题的地方，测试时一定要设计不同的数据进行测试。 安全性测试 SQL注入（比如登陆页面） XSS跨网站脚本攻击：程序或数据库没有对一些特殊字符进行过滤或处理，导致用户所输入的一些破坏性的脚本语句能够直接写进数据库中，浏览器会直接执行这些脚本语句，破坏网站的正常显示，或网站用户的信息被盗,构造脚本语句时，要保证脚本的完整性。 123 document.write(&quot;abc&quot;) &lt;script&gt;alter(&quot;abc&quot;)&lt;/script&gt; URL地址后面随便输入一些符号，并尽量是动态参数靠后 验证码更新问题 现在的Web应用系统基本采用先注册，后登陆的方式。因此，必须测试有效和无效的用户名和密码，要注意到是否大小写敏感，可以试多少次的限制，是否可以不登陆而直接浏览某个页面等。 Web应用系统是否有超时的限制，也就是说，用户登陆后在一定时间内（例如15分钟）没有点击任何页面，是否需要重新登陆才能正常使用。 为了保证Web应用系统的安全性，日志文件是至关重要的。需要测试相关信息是否写进了日志文件、是否可追踪。 当使用了安全套接字时，还要测试加密是否正确，检查信息的完整性。 服务器端的脚本常常构成安全漏洞，这些漏洞又常常被黑客利用。所以，还要测试没有经过授权，就不能在服务器端放置和编辑脚本的问题。 性能测试 连接速度测试用户连接到Web应用系统的速度根据上网方式的变化而变化，他们或许是电话拨号，或是宽带上网。当下载一个程序时，用户可以等较长的时间，但如果仅仅访问一个页面就不会这样。如果Web系统响应时间太长（例如超过5秒钟），用户就会因没有耐心等待而离开。 另外，有些页面有超时的限制，如果响应速度太慢，用户可能还没来得及浏览内容，就需要重新登陆了。而且，连接速度太慢，还可能引起数据丢失，使用户得不到真实的页面。 负载测试负载测试是为了测量Web系统在某一负载级别上的性能，以保证Web系统在需求范围内能正常工作。负载级别可以是某个时刻同时访问Web系统的用户数量，也可以是在线数据处理的数量。例如：Web应用系统能允许多少个用户同时在线？如果超过了这个数量，会出现什么现象？Web应用系统能否处理大量用户对同一个页面的请求？ 压力测试负载测试应该安排在Web系统发布以后，在实际的网络环境中进行测试。因为一个企业内部员工，特别是项目组人员总是有限的，而一个Web系统能同时处理的请求数量将远远超出这个限度，所以，只有放在Internet上，接受负载测试，其结果才是正确可信的。进行压力测试是指实际破坏一个Web应用系统，测试系统的反映。压力测试是测试系统的限制和故障恢复能力，也就是测试Web应用系统会不会崩溃，在什么情况下会崩溃。黑客常常提供错误的数据负载，直到Web应用系统崩溃，接着当系统重新启动时获得存取权。压力测试的区域包括表单、登陆和其他信息传输页面等。 负载/压力测试应该关注什么 瞬间访问高峰如果您的站点用于公布彩票的抽奖结果，最好使系统在中奖号码公布后的一段时间内能够响应上百万的请求。负载测试工具能够模拟X个用户同时访问测试站点。 每个用户传送大量数据网上书店的多数用户可能只订购1-5书，但是大学书店可能会订购5000本有关心理学介绍的课本?或者一个祖母为她的50个儿孙购买圣诞礼物(当然每个孩子都有自己的邮件地址)系统能处理单个用户的大量数据吗? 长时间的使用如果站点用于处理鲜花订单，那么至少希望它在母亲节前的一周内能持续运行。如果站点提供基于web的email服务，那么点最好能持续运行几个月，甚至几年。可能需要使用自动测试工具来完成这种类型的测试，因为很难通过手工完成这些测试。你可以想象组织100个人同时点击某个站点。但是同时组织100000个人呢。通常，测试工具在第二次使用的时候，它创造的效益，就足以支付成本。而且，测试工具安装完成之后，再次使用的时候，只要点击几下。采取措施：采用性能测试工具WAS、ACT，LR等协助进行测试 测试中应该注意的其他情况 在测试时，与网络有关的步骤或者模块必须考虑到断网的情况 每个页面都有相应的Title，不能为空，或者显示“无标题页” 在测试的时候要考虑到页面出现滚动条时，滚动条上下滚动时，页面是否正常 URL不区分大小写，大小写不敏感 对于电子商务网站，当用户并发购买数量大于库存的数量时，系统如何处理 测试数据避免单纯输入“123”、“abc“之类的，让测试数据尽量接近实际 进行测试时，尽量不要用超级管理员进行测试，用新建的用户进行测试。测试人员尽量不要使用同一个用户进行测试 提示信息是否完整、正确、详细 帮助信息：是否提供帮助信息，帮助信息的表现形式（页面文字、提示信息、帮助文件），帮助信息是否正确、详细 可扩展性：是否由升级的余地，是否保留了接口 稳定性：运行所需的软硬件配置，占用资源情况，出现问题时的容错性，对数据的保护 运行速度：运行的快慢，带宽占用情况]]></content>
      <categories>
        <category>软件测试</category>
      </categories>
      <tags>
        <tag>测试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[app测试点总结]]></title>
    <url>%2F2019%2F01%2F23%2Fapp%E6%B5%8B%E8%AF%95%E7%82%B9%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[功能性测试 评审需求，多方面考虑，整理出内在外在以及非功能性的直接间接功能点，对比需求，提取测试点 根据常用的一些分析方法，等价类边界值判定表因果图场景法等方法，设计测试用例，对提取的功能点进行覆盖 测试各个阶段不断跟踪缺陷，做好用例的更新迭代和不断变更需求所带来的业务或者需求的错误 运行 App安装完成后的试运行，可正常打开软件 App打开测试，是否有加载状态进度提示 App打开速度测试，速度是否可观 App页面间的切换是否流畅，逻辑是否正确 注册: 用户名密码长度、注册后的提示页面、前台注册页面和后台的管理页面数据是否一致、注册后，在后台管理中页面提示 登录: 使用合法的用户登录系统、系统是否允许多次非法的登陆，是否有次数限制、使用已经登陆的账号登陆系统是否正确处理、使用禁用的账号登陆系统是否正确处理、用户名、口令（密码）错误或漏填时能否登陆、删除或修改后的用户，原用户登陆、不输入用户口令和用户、重复点（确定或取消按钮）是否允许登陆、登陆后，页面中登陆信息、页面中有注销按钮、登陆超时的处理 注销: 注销原模块，新的模块系统能否正确处理、终止注销能否返回原模块，原用户、注销原用户，新用户系统能否正确处理、使用错误的账号、口令、无权限的被禁用的账号进行注销 应用前后台切换 APP切换到后台，再回到 app，检查是否停留在上一次操作界面 APP切换到后台，再回到 app，检查功能及应用状态是否正常 app切换到后台，再回到前台时，注意程序是否崩溃，功能状态是否正常，尤其是对于从后台切换回前台数据有自动更新的时候 手机锁屏解屏后进入app注意是否会崩溃，功能状态是否正常，尤其是对于从后台切换回前台数据有自动更新的时候 当App使用过程中有电话进来中断后再切换到app，功能状态是否正常 当杀掉app进程后，再开启app，观察app能否正常启动 出现必须处理的提示框后，切换到后台，再切换回来，检查提示框是否还存在，有时候会出现应用自动跳过提示框的缺陷 对于有数据交换的页面，每个页面都必需要进行前后台切换、锁屏的测试，这种页面最容易出现崩溃 免登录很多应用提供免登录功能，当应用开启时自动以上一次登录的用户身份来使用app 考虑无网络情况时能否正常进入免登录状态 切换用户登录后，要校验用户登录信息及数据内容是否相应更新，确保原用户退出 一个帐户只允许登录一台机器。所以，需要检查一个帐户登录多台手机的情况。原手机里的用户需要被踢出，给出友好提示 app切换到后台，再切回前台的校验 密码更换后，检查有数据交换时是否进行了有效身份的校验 支持自动登录的应用在进行数据交换时，检查系统是否能自动登录成功并且数据操作无误 检查用户主动退出登录后，下次启动app，应停留在登录界面 数据更新 需要确定哪些地方需要提供手动刷新，哪些地方需要自动刷新，哪些地方需要手动+自动刷新 确定哪些地方从后台切换回前台时需要进行数据更新 根据业务、速度及流量的合理分配，确定哪些内容需要实时更新，哪些需要定时更新 确定数据展示部分的处理逻辑，是每次从服务端请求，还是有缓存到本地，这样才能有针对性的进行相应测试 检查有数据交换的地方，均有相应的异常处理 离线浏览 在无网络情况可以浏览本地数据 退出app再开启app时能正常浏览 切换到后台再切回前台可以正常浏览 锁屏后再解屏回到应用前台可以正常浏览 App更新 当客户端有新版本时，有更新提示 当版本为非强制升级版时，用户可以取消更新，老版本能正常使用。用户在下次启动app时，仍能出现更新提示 当版本为强制升级版时，当给出强制更新后用户没有做更新时，退出客户端。下次启动app时，仍出现强制升级提示 当客户端有新版本时，在本地不删除客户端的情况下，直接更新检查是否能正常更新 当客户端有新版本时，在本地不删除客户端的情况下，检查更新后的客户端功能是否是新版本 当客户端有新版本时，在本地不删除客户端的情况下，检查资源同名文件如图片是否能正常更新成最新版本。如果以上无法更新成功的，也都属于缺陷 定位、照相机服务 App有用到相机，定位服务时，需要注意系统版本差异 有用到定位服务、照相机服务的地方，需要进行前后台的切换测试，检查应用是否正常 当定位服务没有开启时，使用定位服务，会友好性弹出是否允许设置定位提示。当确定允许开启定位时，能自动跳转到定位设置中开启定位服务 测试定位、照相机服务时，需要采用真机进行测试 时间测试 客户端可以自行设置手机的时区、时间，因此需要校验该设置对app的影响 中国为东8区，所以当手机设置的时间非东8区时，查看需要显示时间的地方，时间是否展示正确，应用功能是否正常 时间一般需要根据服务器时间再转换成客户端对应的时区来展示，这样的用户体验比较好 推送测试 检查push消息是否按照指定的业务规则发送 检查不接受推送消息时，检查用户不会再接收到push 如果用户设置了免打扰的时间段，检查在免打扰时间段内，用户接收不到PUSH、在非免打扰时间段，用户能正常收到 push 当push消息是针对登录用户的时候，需要检查收到的push与用户身份是否相符，没有错误地将其它人的消息推送过来。一般情况下，只对手机上最后一个登录用户进行消息推送。 测试push时，需要采用真机进行测试 兼容性测试 android版本的兼容性 手机分辨率兼容性 网络的兼容性：2G\3G\4G\WIFI,弱网下、断网时 app跨版本的兼容性 各种设备品牌机型系统版本等兼容 与本地及主流App是否兼容 性能测试 压力测试 电量流量测试 cup、内存消耗 app启动时长 crash率 内存泄漏 压服务器端接口及客户端在不同网络环境下响应速度 极限测试：各种边界情况下验证app的响应能力，如：低电量、储存满。弱网等情况 响应能力测试：验证各种情况下不同操作能否满足用户响应需求，比如App安装、卸载的响应时间、App各类功能性操作的影响时间 压力测试：反复长期操作下，系统该资源的使用情况，比如App反复进行安装卸载，查看系统资源是否正常、其他功能反复进行操作，查看系统资源是否正常 网络测试 外网测试主要现实模拟客户使用网络环境，检验客户单程序在实际网若环境中使用情况及进行业务操作 外网测试主要覆盖到wifi\2G\3G\4G,.net\wap、电信\移动\联通、所有可能的组合进行测试 尽可能全面覆盖用户的使用场景，测试用例中需要包含不同网络排列组合的各种可能 还有模拟信号被屏蔽时候。客户端的影响等。还有做外包场景测试，在高山、丘陵、火车上等特殊环境下进行全面测试 接口性测试 client端和service端的交互 client端的数据更新和service端的数据是否一致 client端更新时连接中断 client端更新时service端宕机 业务逻辑测试 主要测试客户端业务能否正常完成 异常测试 交互异常性测试：客户端作为手机特性测试，包括被打扰的情况；如来电、来短信、低电量测试等，还要注意手机端硬件上，如：待机，插拔数据线、耳机等操作不会影响客户端 异常性测试：主要包含了断网、断电、服务器异常等情况下，客户端能否正常处理，保证数据正确性 回归测试 Bug修复后且在新版本发布后需要进行回归测试 Bug修复后的回归测试在交付前、要进行全量用例的回归测试 升级更新测试 每次app版本迭代更新时，配合不同网络环境，及不同更新权限（强制更新，不强制更新），进行下载、安装、更新、启动运行等测试 测试升级后的功能是否与需求说明一样 测试与升级模块相关的模块的功能是否与需求一致 升级安装意外情况的测试（如死机、断电、重启） 升级界面的UI测试 不同操作系统间的升级测试 支付测试 支付结果的确认，数据库查询 请求报文是否加密 不同场景的支付，金额足够、金额不足、重复支付、无网支付、弱网支付、同账号多平台一起支付、余额宝微信信用卡等多种支付方式、不同支付方式的组合、密码正确/错误、支付上限等情况 安全测试 软件权限 扣费风险：包括发送短信、拨打电话、连接网络等 隐私泄露风险：包括访问手机信息、访问联系人信息等 对App的输入有效性校验、认证、授权、敏感数据存储、数据加密等方面进行检测 限制/允许使用手机功能接人互联网 限制/允许使用手机发送接受信息功能 限制/允许应用程序来注册自动启动应用程序 限制或使用本地连接 限制/允许使用手机拍照或录音 限制/允许使用手机读取用户数据 限制/允许使用手机写人用户数据 检测App的用户授权级别、数据泄漏、非法授权访问等 安装与卸载安全性 应用程序应能正确安装到设备驱动程序上 能够在安装设备驱动程序上找到应用程序的相应图标 是否包含数字签名信息 JAD文件和JAR包中包含的所有托管属性及其值必需是正确的 JAD文件显示的资料内容与应用程序显示的资料内容应一致 安装路径应能指定 没有用户的允许,应用程序不能预先设定自动启动 卸载是否安全,其安装进去的文件是否全部卸载 卸载用户使用过程中产生的文件是否有提示 其修改的配置信息是否复原 卸载是否影响其他软件的功能 卸载应该移除所有的文件 数据安全性 当将密码或其他的敏感数据输人到应用程序时,其不会被储存在设备中,同时密码也不会被解码 输人的密码将不以明文形式进行显示 密码,信用卡明细,或其他的敏感数据将不被储存在它们预输人的位置上 当应用程序处理信用卡明细,或其他的敏感数据时,不以明文形式将数据写到其它单独的文件或者临时文件中 防止应用程序异常终止而又没有侧除它的临时文件,文件可能遭受人侵者的袭击,然后读取这些数据信息 当将敏感数据输人到应用程序时,其不会被储存在设备中 备份应该加密,恢复数据应考虑恢复过程的异常通讯中断等,数据恢复后再使用前应该经过校验 应用程序应考虑系统或者虚拟机器产生的用户提示信息或安全警告 如果数据库中重要的数据正要被重写,应及时告知用户 应用程序读和写数据正确 通讯安全性 在运行其软件过程中,如果有来电、SMS、EMS、MMS、蓝牙、红外等通讯或充电时,是否能暂停程序，优先处理通信,并在处理完毕后能正常恢复软件,继续其原来的功能 当创立连接时,应用程序能够处理因为网络连接中断,进而告诉用户连接中断的情况 应用程序将保持工作到通讯超时,进而发送给用户一个错误信息指示有连接错误 HTTP、HTTPS覆盖测试 人机接口安全性 返回菜单总保持可用 命令有优先权顺序 声音的设置不影响应用程序的功能 应用程序必需利用目标设备适用的全屏尺寸来显示上述内容 应用程序必需能够处理不可预知的用户操作,例如错误的操作和同时按下多个键 安装、卸载测试 安装 软件在不同操作系统（Palm OS、Symbian、Linux、Android、iOS、Black Berry OS 6.0、Windows Phone 7）下安装是否正常 软件安装后的是否能够正常运行，安装后的文件夹及文件是否写到了指定的目录里 软件安装各个选项的组合是否符合概要设计说明 软件安装向导的 UI测试 软件安装过程是否可以取消，点击取消后，写入的文件是否如概要设计说明处理 软件安装过程中意外情况的处理是否符合需求（如死机，重启，断电） 安装空间不足时是否有相应提示 安装后没有生成多余的目录结构和文件 对于需要通过网络验证之类的安装，在断网情况下尝试一下 还需要对安装手册进行测试，依照安装手册是否能顺利安装 卸载 直接删除安装文件夹卸载是否有提示信息 测试系统直接卸载程序是否有提示信息 测试卸载后文件是否全部删除所有的安装文件夹 卸载过程中出现的意外情况的测试（如死机、断电、重启） 卸载是否支持取消功能，单击取消后软件卸载的情况 系统直接卸载 UI测试，是否有卸载状态进度条提示 UI测试 用户界面（菜单、对话框、窗口）等布局，风格是否满足用户需求，文字位置，描述是否正确，界面美观程度，文字图片组合是否合理 用户友好性、人性化、便于操作等 导航测试 按钮、对话框、列表和窗口等；或在不同的连接页面之间需要导航 是否易于导航，导航是否直观 是否需要搜索引擎 导航帮助是否准确直观 导航与页面结构、菜单、连接页面的风格是否一致 图形测试 横向比较。各控件操作方式统一 自适应界面设计，内容根据窗口大小自适应 页面标签风格是否统一 页面是否美观 页面的图片应有其实际意义而要求整体有序美观 图片质量要高且图片尺寸在设计符合要求的情况下应尽量小 界面整体使用的颜色不宜过多 内容测试 输入框说明文字的内容与系统功能是否一致 文字长度是否加以限制 文字内容是否表意不明 是否有错别字 信息是否为中文显示 是否有敏感性词汇、关键词 是否有敏感性图片，如：涉及版权、专利、隐私等图片 交叉事件测试 多个 App同时运行是否影响正常功能 App运行时前/后台切换是否影响正常功能 App运行时拨打/接听电话 App运行时发送/接收信息 App运行时发送/收取邮件 App运行时切换网络（2G、3G、wifi） App运行时浏览网络 App运行时使用蓝牙传送/接收数据 App运行时使用相机、计算器等手机自带设备 用户体验测试 是否有空数据界面设计，引导用户去执行操作 是否滥用用户引导 是否有不可点击的效果，如：你的按钮此时处于不可用状态，那么一定要灰掉，或者拿掉按钮，否则会给用户误导 菜单层次是否太深 交互流程分支是否太多 相关的选项是否离得很远 一次是否载入太多的数据 界面中按钮可点击范围是否适中 标签页是否跟内容没有从属关系，当切换标签的时候，内容跟着切换 操作应该有主次从属关系 是否定义 Back的逻辑。涉及软硬件交互时，Back键应具体定义 是否有横屏模式的设计，应用一般需要支持横屏模式，即自适应设计 硬件环境测试 手势操作测试 手机开锁屏对运行中的 App的影响 切换网络对运行中的 App的影响 运行中的 App前后台切换的影响 多个运行中的 App的切换 App运行时关机 App运行时重启系统 App运行时充电 App运行时kill掉进程再打开 网络环境 无网络时，执行需要网络的操作，给予友好提示，确保程序不出现crash 内网测试时，要注意选择到外网操作时的异常情况处理 在网络信号不好时，检查功能状态是否正常，确保不因提交数据失败而造成crash 在网络信号不好时，检查数据是否会一直处于提交中的状态，有无超时限制。如遇数据交换失败时要给予提示 在网络信号不好时，执行操作后，在回调没有完成的情况下，退出本页面或者执行其他操作的情况，有无异常情况。此问题也会经常出现程序crash 服务器宕机或出现404、502等情况下的测试后台服务牵涉到 DNS、空间服务商的情况下会影响其稳定性，如：当出现域名解析故障时，你对后台 API的请求很可能就会出现 404错误，抛出异常。这时需要对异常进行正确的处理，否则可能会导致程序不能正常工作。]]></content>
      <categories>
        <category>软件测试</category>
      </categories>
      <tags>
        <tag>测试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[用appium测试app]]></title>
    <url>%2F2019%2F01%2F22%2F%E7%94%A8appium%E6%B5%8B%E8%AF%95app%2F</url>
    <content type="text"><![CDATA[appium简介 关于appium的一些介绍已经在selenium和appium内部原理总结中总结了，appium是一个c/s架构的工具，server端是一个node.js启动的服务器，client端是使用对应开发包写的脚本，脚本发送请求给server，server操作设备端的app 环境搭建node.js1234ruby -e &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)&quot;brew install nodenode -vnpm -v java在官网下载jdk并安装安装完后可在/Library/Java/JavaVirtualMachines/目录下找到对应的jdk目录在/etc/profile中添加环境变量example:123export JAVA_HOME=/Library/Java/JavaVirtualMachines/jdk1.8.0_40.jdk/Contents/Homeexport PATH=$JAVA_HOME/bin:$PATHsource /etc/profile android sdk在这里下载下载完后解压进入tools目录，运行./android sdk安装platform-tools、build-tools在~/.bash_profile中添加环境变量1234export ANDROID_HOME=mysdk_dirPATH=$PATH:$ANDROID_HOME/tools:$ANDROID_HOME/platform-toolsexport PATHsource ~/.bash_profile appium serverDesktop版本：下载地址命令行版本： npm install appium -g appium clientpython版本：pip install Appium-Python-Client appium-doctornpm install appium-doctor -g这个命令可以检查当前appium环境是否配置正确可能出错的地方：jdk地址、android sdk地址、node.js android 模拟器夜神：下载地址打开模拟器后使用adb devices可能会找不到模拟器，把android sdk中platform-tool中的adb重命名成nox_adb覆盖掉夜神中的nox_adb点击设置，关于平板电脑，连续点击 安卓版本，打开开发者模式重启adb就能找到模拟器设备了 测试实例等待更新]]></content>
      <categories>
        <category>软件测试</category>
      </categories>
      <tags>
        <tag>测试</tag>
        <tag>appium</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[各种日常总结]]></title>
    <url>%2F2019%2F01%2F21%2F%E5%90%84%E7%A7%8D%E6%97%A5%E5%B8%B8%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[linux下查找java的安装路径时间: 2019年1月21日15:03:05 配置appium环境需要添加JAVA_HOME这个环境变量，但是忘记了安装的路径which java、whereis java都只能找到java的执行路径可行的方式: 12ls -lrt /usr/bin/javals -lrt /etc/alternatives/java 统计一个文件夹下的所有文件，不包括子文件夹下的文件时间: 2019年1月25日16:12:53 12ls -l | wc -l# 数量需要减1 xxx]]></content>
      <categories>
        <category>总结</category>
      </categories>
      <tags>
        <tag>总结</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[selenium和appium内部原理总结]]></title>
    <url>%2F2019%2F01%2F21%2Fselenium%E5%92%8Cappium%E5%86%85%E9%83%A8%E5%8E%9F%E7%90%86%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[selenium和appium内部原理总结 为什么会有这篇文章？前段时间学习了selenium的使用，今天开始接触appium看到appium的原理后产生了疑惑：现在的selenium是通过webdriver来操作驱动浏览器的，然而appium有一个server的概念那么为什么没有app driver这个东西呢？ selenium早期的selenium 早期的selenium主要是指selenium1.0的版本，这个版本主要由Selenium IDE + Selenium Grid + SeleniumRC组成seleniumRC就是后来被webdriver取代的一个代理serverRC == Remote Control 远程控制早期Selenium 引入了 Remote Control Server 这样一个代理 Server，JavaScript 脚本注入和与 Server 通讯都通过这个代理 Server 来进行，JavasScript可以获取并调用页面的任何元素，Selenium启动一个Server，将操作Web元素的API调用转化为一段段JavaScript，在Selenium内核启动浏览器之后注入这段JS缺点：但是JS注入速度不理想，稳定性大大依赖于Selenium内核对API翻译成的JS质量高低引入代理Remote Control Server是因为“同源策略”的限制，通过这个代理服务器来“欺骗”远程Server，达到使其以为是从同一个地方load代码以正确返回请求数据的效果 seleniumRC的原理 Selenium RC Server 启动一个浏览器（或是已经使用中），并注入js代码 将测试脚本代码传到客户端的 Selenium-Core 中 Selenium-Core 翻译并解析执行用户录制的操作 让代理 Server 进行通讯 Remote Control Server 负责跟远程 Web 应用服务器进行通讯 seleniumRC的组成 Selenium Server(Launcher、Http Proxy、Selenium Core) Client Libraries(用来控制server) seleniumRC的工作流程 测试用例通过Client Libraries的接口向Selenium Server发送Http请求，要求和Selenium Server建立连接 Selenium Server的Launcher启动浏览器，把Selenium Core加载入浏览器页面中，并发浏览器的代理设置为Selenium Server的Http Proxy。 测试用例通过Client Libraries的接口向Selenium Server发送Http请求，Selenium Server对请求进行解析，然后通过Http Proxy发送JS命令通知Selenium Core执行操作浏览器的动作 Selenium Core接收到指令后，执行操作 浏览器收到新的页面请求信息，于是发送Http请求，请求新的web页面。Selenium Server会接收到所有由它启动的浏览器发动的请求 Selenium Server接收到浏览器发送的Http请求后，自己重组Http请求，获取对应的web页面 Selenium Server的Http Proxy把接收的Web页面返回给浏览器 现在的selenium selenium3.0以后移除了seleniumRC，取而代之的是webdriver用一张图来展示selenium3.0的运行原理这里讲到的是测试脚本和浏览器的交互，客户端开始运行驱动浏览器的脚本的时候，这时浏览器收到请求开始启动并开启侦听端口，并自动创建session，保持浏览器和对应客户端的会话连接,然后客户端运行脚本，向浏览器发送http请求，浏览器解析请求，根据脚本内容做出相应操作，返回response。这时客户端根据response选择结束还是继续执行tips: webdriver操作浏览器、页面采用的协议：the webdriver wire protocol Client和Server的通信协议：HTTP HTTP传输的数据内容为遵循WP协议json格式数据 浏览器驱动实现了webdriver协议的api appiumappium和selenium之间的不同 appium本身就是一个server，而selenium废弃了server，用webdriver来驱动浏览器 appium工作原理 当开启appium服务器的同时就开启了监听端口；我们运行脚本的时候，调用任何的appiumAPI，都会向Appium Server端post一条HTTP请求，请求内容就是根据webdriver wire protocol协议规定的一条JSON格式的数据；Appium Server端接收到请求后，解析出JSON数据并发送到手机端；手机端上已经由BootStrap.jar(iOS为BootStrip.js)开启的socket服务器监听相应的端口，BootStrap.jar在appium每个session第一次访问手机端的时候会自动安装；手机端接收到对应的请求后，通过BootStrap.jar翻译成UIAutomator能执行的命令，然后通过UIAutomator处理并操作APP完成测试。 appium的几个概念 appium/appium server 一般所说的appium其实是一个基于node.js的web服务器，它是测试脚本和设备端交互的桥梁用npm install -g appium 安装的是命令行的没有界面的appium server appium GUI 它是把没有界面的appium server封装出了一个图形界面，方便操作，但是现在已经被appium desktop所取代 appium Desktop 它是一款适用于Mac，Windows和Linux的开源应用程序，它以美观而灵活的用户界面为您提供appium server的强大功能 appium client 第1点中说到，appium其实是一个sweb server，server是接收请求来操作设备端的app的，既然有了server那么一定会有client这个client就是我们写测试脚本时导入的包python中可以运行 pip install Appium-Python-Client 来安装 Android 和 iOS]]></content>
      <categories>
        <category>软件测试</category>
      </categories>
      <tags>
        <tag>测试</tag>
        <tag>appium</tag>
        <tag>selenium</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Dockerfile部署web应用]]></title>
    <url>%2F2019%2F01%2F19%2FDockerfile%E9%83%A8%E7%BD%B2web%E5%BA%94%E7%94%A8%2F</url>
    <content type="text"><![CDATA[Dockerfile部署web应用 在记录一次web测试这一篇博文中，我把此次测试所产出的文件都放在了自己的服务器上，并提供了下载接口，正好最近在学习docker，今天我把这个web应用用docker跑起来。 编写Dockerfile1234567FROM python # 拉取python基础镜像COPY . /server/ # 将当前项目文件加下的所有文件拷贝到docker容器中的server文件夹WORKDIR /server # 容器内切换到server目录RUN pip install flask # 在镜像安装flaskRUN pip install gunicorn # 在镜像中安装gunicornEXPOSE 8081 # 暴露出8081端口CMD gunicorn -b 0.0.0.0:9998 -w 4 server:app # 最终运行服务器的命令 编译docker镜像1docker build -t test:v1 # test:v1 --&gt; 自定义镜像名:标签 运行容器1docker run -d --name test_server -p 8081:8081 test:v1 访问 访问ip:port即可]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MarkDown语法]]></title>
    <url>%2F2019%2F01%2F16%2FMarkDown%E8%AF%AD%E6%B3%95%2F</url>
    <content type="text"><![CDATA[Markdown是一种纯文本格式的标记语言。通过简单的标记语法，它可以使普通文本内容具有一定的格式。 一、标题在想要设置为标题的文字前面加#来表示一个#是一级标题，二个#是二级标题，以此类推。支持六级标题。 注：标准语法一般在#后跟个空格再写文字，貌似简书不加空格也行。 示例： # 这是一级标题 ## 这是二级标题 ### 这是三级标题 #### 这是四级标题 ##### 这是五级标题 ###### 这是六级标题 效果如下： 这是一级标题这是二级标题这是三级标题这是四级标题这是五级标题这是六级标题 二、字体 加粗 要加粗的文字左右分别用两个*号包起来 斜体 要倾斜的文字左右分别用一个*号包起来 斜体加粗 要倾斜和加粗的文字左右分别用三个*号包起来 删除线 要加删除线的文字左右分别用两个~~号包起来 示例： **这是加粗的文字** *这是倾斜的文字*` ***这是斜体加粗的文字*** ~~这是加删除线的文字~~ 效果如下： 这是加粗的文字这是倾斜的文字这是斜体加粗的文字这是加删除线的文字 三、引用在引用的文字前加&gt;即可。引用也可以嵌套，如加两个&gt;&gt;三个&gt;&gt;&gt;n个…貌似可以一直加下去，但没神马卵用 示例： &gt;这是引用的内容 &gt;&gt;这是引用的内容 &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;这是引用的内容 效果如下： 这是引用的内容 这是引用的内容 这是引用的内容 四、分割线三个或者三个以上的 - 或者 * 都可以。 示例： --- ---- *** ***** 效果如下：可以看到，显示效果是一样的。 五、图片语法： ![图片alt](图片地址 &apos;&apos;图片title&apos;&apos;) 图片alt就是显示在图片下面的文字，相当于对图片内容的解释。 图片title是图片的标题，当鼠标移到图片上时显示的内容。title可加可不加 示例： ![blockchain](https://ss0.bdstatic.com/70cFvHSh_Q1YnxGkpoWK1HF6hhy/it/ u=702257389,1274025419&amp;fm=27&amp;gp=0.jpg &quot;区块链&quot;) 效果如下： blockchain 上传本地图片直接点击导航栏的图片标志，选择图片即可 六、超链接语法： [超链接名](超链接地址 &quot;超链接title&quot;) title可加可不加 示例： [简书](http://jianshu.com) [百度](http://baidu.com) 效果如下： 简书百度 注：Markdown本身语法不支持链接在新页面中打开，貌似简书做了处理，是可以的。别的平台可能就不行了，如果想要在新页面中打开的话可以用html语言的a标签代替。 &lt;a href=&quot;超链接地址&quot; target=&quot;_blank&quot;&gt;超链接名&lt;/a&gt; 示例 &lt;a href=&quot;https://www.jianshu.com/u/1f5ac0cf6a8b&quot; target=&quot;_blank&quot;&gt;简书&lt;/a&gt; 七、列表 无序列表 语法：无序列表用 - + * 任何一种都可以 - 列表内容 + 列表内容 * 列表内容 注意：- + * 跟内容之间都要有一个空格 效果如下： 列表内容 列表内容 列表内容 有序列表 语法：数字加点 1.列表内容 2.列表内容 3.列表内容 注意：序号跟内容之间要有空格 效果如下： 1.列表内容2.列表内容3.列表内容 列表嵌套 上一级和下一级之间敲三个空格即可 一级无序列表内容 二级无序列表内容 二级无序列表内容 二级无序列表内容 一级无序列表内容 二级有序列表内容 二级有序列表内容 二级有序列表内容 一级有序列表内容 二级无序列表内容 二级无序列表内容 二级无序列表内容 一级有序列表内容 二级有序列表内容 二级有序列表内容 二级有序列表内容 八、表格语法： 表头|表头|表头 ---|:--:|---: 内容|内容|内容 内容|内容|内容 第二行分割表头和内容。 - 有一个就行，为了对齐，多加了几个 文字默认居左 -两边加：表示文字居中 -右边加：表示文字居右 注：原生的语法两边都要用 | 包起来。此处省略 示例： 姓名|技能|排行 --|:--:|--: 刘备|哭|大哥 关羽|打|二哥 张飞|骂|三弟 九、代码语法：单行代码：代码之间分别用一个反引号包起来 `代码内容` 代码块：代码之间分别用三个反引号包起来，且两边的反引号单独占一行 (123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051 代码... 代码... 代码... (```) &gt; 注：为了防止转译，前后三个反引号处加了小括号，实际是没有的。这里只是用来演示，实际中去掉两边小括号即可。示例：单行代码 `create database hero;` 代码块 (```) function fun()&#123; echo &quot;这是一句非常牛逼的代码&quot;; &#125; fun(); (```) 效果如下：单行代码`create database hero;`代码块 function fun()&#123; echo &quot;这是一句非常牛逼的代码&quot;; &#125; fun(); 十、流程图===== ```flow st=&gt;start: 开始 op=&gt;operation: My Operation cond=&gt;condition: Yes or No? e=&gt;end st-&gt;op-&gt;cond cond(yes)-&gt;e cond(no)-&gt;op &amp;]]></content>
      <categories>
        <category>markdown</category>
      </categories>
      <tags>
        <tag>markdown</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[用docker安装mysql5.6，并远程连接]]></title>
    <url>%2F2019%2F01%2F16%2F%E7%94%A8docker%E5%AE%89%E8%A3%85mysql5-6%EF%BC%8C%E5%B9%B6%E8%BF%9C%E7%A8%8B%E8%BF%9E%E6%8E%A5%2F</url>
    <content type="text"><![CDATA[用docker安装mysql:5.6镜像 运行命令: docker pull mysql:5.6 查看下载的docker镜像 运行命令: docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEmysql 5.6 27e29668a08a 2 weeks ago 256MB 创建docker容器 tips: MySQL(5.7.19)的默认配置文件是 /etc/mysql/my.cnf 文件。如果想要自定义配置，建议向 /etc/mysql/conf.d 目录中创建 .cnf文件。新建的文件可以任意起名，只要保证后缀名是 cnf 即可。新建的文件中的配置项可以覆盖 /etc/mysql/my.cnf 中的配置项。 创建要映射到容器中的.cnf文件 mkdir -p docker_v/mysql/confcd docker_v/mysql/conftouch my.cnf 启动容器 docker run -p 3306:3306 –name mysql -v /opt/docker_v/mysql/conf:/etc/mysql/conf.d -e MYSQL_ROOT_PASSWORD=123456 -d imageID -p 3306:3306：将容器的3306端口映射到主机的3306端口-v /opt/docker_v/mysql/conf:/etc/mysql/conf.d：将主机/opt/docker_v/mysql/conf目录挂载到容器的/etc/mysql/conf.d-e MYSQL_ROOT_PASSWORD=123456：初始化root用户的密码-d: 后台运行容器，并返回容器IDimageID: mysql镜像ID 查看启动的mysql容器 运行命令: docker ps navicat远程连接mysql新建连接 点击新建连接，选择mysql 更改配置 在常规选项中，输入主机名，mysql的端口号，mysql的用户名和密码在SSH选项中，输入主机ip，主机端口号，主机用户名和密码点击测试连接]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[记录一次web测试]]></title>
    <url>%2F2019%2F01%2F14%2F%E8%AE%B0%E5%BD%95%E4%B8%80%E6%AC%A1web%E6%B5%8B%E8%AF%95%2F</url>
    <content type="text"><![CDATA[SegmentFault Web 测试]]></content>
      <categories>
        <category>软件测试</category>
      </categories>
      <tags>
        <tag>测试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[selenium中的window handle]]></title>
    <url>%2F2019%2F01%2F14%2Fselenium%E4%B8%AD%E7%9A%84window-handle%2F</url>
    <content type="text"><![CDATA[webdriver之window handle 实例化一个webdriver后相当于开启一个浏览器进程，一个实例化的driver可以有多个window窗口，在浏览器中显示为多个标签，比如点击一个链接 网易，会打开一个新的窗口 webdriver类中的所有方法有一个前提条件是：都作用于某一window handle window handle是惰性的，不会自动切换，如果打开了一个新的窗口，想在新窗口上获取某一元素，需要先手动切换window handle，driver.switch_to.window(xxx_handle) 用driver.window_handles可以获取所有窗口句柄 窗口句柄是浏览器拥有的，元素没有窗口句柄 window handle示例`import time from selenium import webdriver from selenium.webdriver.common.action_chains import ActionChains def demo(): driver = webdriver.Chrome() driver.implicitly_wait(10) driver.get(&apos;[http://baidu.com](http://baidu.com)&apos;) print(driver.window_handles) #打开百度后第一次打印窗口句柄 bd_kw = driver.find_element_by_css_selector(&apos;#kw&apos;) bd_sb = driver.find_element_by_css_selector(&apos;#su&apos;) ac = ActionChains(driver) ac.send_keys_to_element(bd_kw, &apos;python&apos;).click(bd_sb).perform() py = driver.find_element_by_xpath(&apos;//*[@id=&quot;2&quot;]/h3/a&apos;) py.click() #在百度中搜索python后打开一个新的窗口 print(driver.window_handles) #第二次打印窗口句柄 time.sleep(5) driver.close() #关闭driver的当前句柄，可以用current_handle查看 print(driver.window_handles) #第三次打印窗口句柄 driver.switch_to.window(driver.window_handles[-1]) #切换window handle print(driver.current_window_handle) #打印current_window_handle，不切换会报异常，因为之前的window已经被我们关闭了 time.sleep(5) driver.quit() if __name__ == &apos;__main__&apos;: demo() ---------------------- &gt;&gt;&gt;[&apos;CDwindow-3711170FE14EB6A64A8D9A51249D8EF6&apos;] #只打开了百度首页，所以只有一个 &gt;&gt;&gt;[&apos;CDwindow-3711170FE14EB6A64A8D9A51249D8EF6&apos;, &apos;CDwindow-1FDDE8A60F9569D82F5A477DCBF6B8E1&apos;] #打开了百度首页和某一个搜索出来的页面，新的页面在新的窗口中，所以有两个 &gt;&gt;&gt;[&apos;CDwindow-1FDDE8A60F9569D82F5A477DCBF6B8E1&apos;] #没切换handle，关闭了第一个window，所以看到，原列表中的第一个元素被删除了，只有新的窗口handle保留下来了 &gt;&gt;&gt;CDwindow-1FDDE8A60F9569D82F5A477DCBF6B8E1 #切换了handle，并打印出current_window_handle` tips： driver的current handle也是惰性的，如果current window handle被关闭，那么current_handle这个值就取不到了，会报异常，需要用手动调用driver.switch_to.window 来显示切换。 如果元素定位失败，要检查一下是不是打开了新的窗口，如果是，则需要切换window handle，因为它不会自动切换。]]></content>
      <categories>
        <category>软件测试</category>
      </categories>
      <tags>
        <tag>测试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Jmeter压测工具使用总结]]></title>
    <url>%2F2019%2F01%2F14%2FJmeter%E5%8E%8B%E6%B5%8B%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[1、常用测试工具对比 1、loadrunner 性能稳定，压测结果及细粒度大，可以自定义脚本进行压测，但是太过于重大，功能比较繁多 2、apache ab(单接口压测最方便) 模拟多线程并发请求,ab命令对发出负载的计算机要求很低，既不会占用很多CPU，也不会占用太多的内存，但却会给目标服务器造成巨大的负载, 简单DDOS攻击等 3、webbench webbench首先fork出多个子进程，每个子进程都循环做web访问测试。子进程把访问的结果通过pipe告诉父进程，父进程做最终的统计结果。 2、Jmeter目录文件讲解 bin:核心可执行文件，包含配置 jmeter.bat: windows启动文件： jmeter: mac或者linux启动文件： jmeter-server：mac或者Liunx分布式压测使用的启动文件 jmeter-server.bat：mac或者Liunx分布式压测使用的启动文件 jmeter.properties: 核心配置文件 extras：插件拓展的包 lib:核心的依赖包 ext:核心包 junit:单元测试包 3、Jmeter基础功能组件介绍线程组和Sampler 1、添加-&gt;threads-&gt;线程组（控制总体并发） 线程数：虚拟用户数。一个虚拟用户占用一个进程或线程 准备时长（Ramp-Up Period(in seconds)）：全部线程启动的时长，比如100个线程，20秒，则表示20秒内100个线程都要启动完成，每秒启动5个线程 循环次数：每个线程发送的次数，假如值为5，100个线程，则会发送500次请求，可以勾选永远循环 2、线程组-&gt;添加-&gt; Sampler(采样器) -&gt; Http （一个线程组下面可以增加几个Sampler） 名称：采样器名称 注释：对这个采样器的描述 web服务器： 默认协议是http 默认端口是80 服务器名称或IP ：请求的目标服务器名称或IP地址 路径：服务器URL Use multipart/from-data for HTTP POST ：当发送POST请求时，使用Use multipart/from-data方法发送，默认不选中。 3、查看测试结果 线程组-&gt;添加-&gt;监听器-&gt;察看结果树 4、Jmeter的断言基本使用 增加断言: 线程组 -&gt; 添加 -&gt; 断言 -&gt; 响应断言 apply to(应用范围): Main sample only: 仅当前父取样器 进行断言，一般一个请求，如果发一个请求会触发多个，则就有sub sample（比较少用） 要测试的响应字段： 响应文本：即响应的数据，比如json等文本 响应代码：http的响应状态码，比如200，302，404这些 响应信息：http响应代码对应的响应信息，例如：OK, Found Response Header: 响应头 模式匹配规则： 包括：是响应文本的一个子集，是包含关系，可以用正则表达式 匹配：使用正则表达式匹配 equals：完全与响应文本相同，不能使用正则表达式 substring：也是包含关系，但是不能使用正则表达式 2、断言结果监听器: 线程组-&gt; 添加 -&gt; 监听器 -&gt; 断言结果 里面的内容是sampler采样器的名称 断言失败，查看结果树任务结果颜色标红通过结果数里面双击不通过的记录，可以看到错误信息) 3、每个sample下面可以加单独的结果树，然后同时加多个断言，最外层可以加个结果树进行汇总 5、结果聚合报告分析 新增聚合报告：线程组-&gt;添加-&gt;监听器-&gt;聚合报告（Aggregate Report） lable: sampler的名称 Samples: 一共发出去多少请求,例如10个用户，循环10次，则是 100 Average: 平均响应时间 Median: 中位数，也就是 50％ 用户的响应时间 90% Line : 90％ 用户的响应不会超过该时间 （90% of the samples took no more than this time. The remaining samples at least as long as this） 95% Line : 95％ 用户的响应不会超过该时间 99% Line : 99％ 用户的响应不会超过该时间 min : 最小响应时间 max : 最大响应时间 Error%：错误的请求的数量/请求的总数 Throughput： 吞吐量——默认情况下表示每秒完成的请求数（Request per Second) 可类比为qps KB/Sec: 每秒接收数据量 6、Jmeter用户自定义变量 1、线程组-&gt;add -&gt; Config Element(配置原件)-&gt; User Definde Variable（用户定义的变量） 2、引用方式${XXX}，在接口中变量中使用 7、CSV数据文件使用 1、线程组-&gt;add -&gt; Config Element(配置原件)-&gt; CSV data set config (CSV数据文件设置) 2、如果是多个参数需要同时引用，则在CSV数据文件里面设置加多个字段 Variabled names(comma-delitited): csv_name,csv_pwd 8、数据库压测操作 配置讲解： 1、Thread Group -&gt; add -&gt; sampler -&gt; jdbc request 添加数据库请求 2、jar包添加 mysql-connector-java-5.1.30.jar 添加连接数据库的jar包 3、JDBC connection Configuration 配置 JDBC request-&gt;add -&gt; config element -&gt; JDBC connection configuration 核心配置 Max Number of connections : 最大连接数 MAX wait :最大等待时间 Auto Commit: 是否自动提交事务 DataBase URL : 数据库连接地址 jdbc:mysql://127.0.0.1:3306/blog JDBC Driver Class : 数据库驱动，选择对应的mysql username:数据库用户名 password:数据库密码 数据库语句： 1、Debug Sampler使用（结果树中查看） Thread Group -&gt; add -&gt; sampler -&gt; debug sampler 2、参数讲解：(sql结尾不要加”;”) 1、variable name of pool declared in JDBC connection configuration（和配置文件同名） 2、Query Type 查询类型 3、parameter values 参数值 4、parameter types 参数类型 5、variable names sql执行结果变量名 6、result variable names 所有结果当做一个对象存储 7、query timeouts 查询超时时间 8、 handle results 处理结果集 9、Jmeter非GUI界面参数 -h 帮助 -n 非GUI模式 -t 指定要运行的 JMeter 测试脚本文件 -l 记录结果的文件 每次运行之前，(要确保之前没有运行过,即xxx.jtl不存在，不然报错) -r Jmter.properties文件中指定的所有远程服务器 -e 在脚本运行结束后生成html报告 -o 用于存放html报告的目录（目录要为空，不然报错） 官方配置文件地址 http://jmeter.apache.org/usermanual/get-started.html 10、Jmeter压测接口的性能优化 1、使用非GUI模式：jmeter -n -t test.jmx -l result.jtl 2、少使用Listener， 如果使用-l参数，它们都可以被删除或禁用。 3、在加载测试期间不要使用“查看结果树”或“查看结果”表监听器，只能在脚本阶段使用它们来调试脚本。 4、包含控制器在这里没有帮助，因为它将文件中的所有测试元素添加到测试计划中。 5、不要使用功能模式,使用CSV输出而不是XML 6、只保存你需要的数据,尽可能少地使用断言 7、如果测试需要大量数据，可以提前准备好测试数据放到数据文件中，以CSV Read方式读取。 8、用内网压测，减少其他带宽影响压测结果 9、如果压测大流量，尽量用多几个节点以非GUI模式向服务器施压 11、Jmeter图形化HTML压测报告dashboard 1、Test and Report informations Source file：jtl文件名 Start Time ：压测开始时间 End Time ：压测结束时间 Filter for display：过滤器 Lable:sampler采样器名称 2、APDEX(Application performance Index) apdex:应用程序性能指标,范围在0~1之间，1表示达到所有用户均满意 T(Toleration threshold)：可接受阀值 F(Frustration threshold)：失败阀值 3、Requests Summary 请求总结 OK:成功率 KO:失败率 4、Statistics 统计数据 lable:sampler采样器名称 samples:请求总数，并发数*循环次数 KO:失败次数 Error%:失败率 Average:平均响应时间 Min:最小响应时间 Max:最大响应时间 90th pct: 90%的用户响应时间不会超过这个值（关注这个就可以了） 2ms,3ms,4,5,2,6,8,3,9 95th pct: 95%的用户响应时间不会超过这个值 99th pct: 99%的用户响应时间不会超过这个值 (存在极端值) throughtput:Request per Second吞吐量 qps received:每秒从服务器接收的数据量 send：每秒发送的数据量 12、Jmeter图形化HTML压测报告Charts报表讲解 1、Over Time（随着时间的变化） Response Times Over Time：响应时间变化趋势 Response Time Percentiles Over Time (successful responses)：最大，最小，平均，用户响应时间分布 Active Threads Over Time：并发用户数趋势 Bytes Throughput Over Time：每秒接收和请求字节数变化，蓝色表示发送，黄色表示接受 Latencies Over Time：平均响应延时趋势 Connect Time Over Time ：连接耗时趋势 2、Throughput Hits Per Second (excluding embedded resources):每秒点击次数 Codes Per Second (excluding embedded resources)：每秒状态码数量 Transactions Per Second：即TPS，每秒事务数 Response Time Vs Request：响应时间和请求数对比 Latency Vs Request：延迟时间和请求数对比 3、Response Times Response Time Percentiles：响应时间百分比 Response Time Overview：响应时间概述 Time Vs Threads：活跃线程数和响应时间 Response Time Distribution：响应时间分布图 13、Jmeter压测注意事项 the firewalls on the systems are turned off or correct ports are opened. 系统上的防火墙被关闭或正确的端口被打开。 all the clients are on the same subnet. 所有的客户端都在同一个子网上。 the server is in the same subnet, if 192.x.x.x or 10.x.x.x IP addresses are used. If the server doesn’t use 192.xx or 10.xx IP address, there shouldn’t be any problems. 如果使用192.x.x.x或10.x.x.x IP地址，则服务器位于同一子网中。 如果服务器不使用192.xx或10.xx IP地址，则不应该有任何问题。 Make sure JMeter can access the server. 确保JMeter可以访问服务器。 Make sure you use the same version of JMeter and Java on all the systems. Mixing versions will not work correctly. 确保在所有系统上使用相同版本的JMeter和Java。 混合版本将无法正常工作。 You have setup SSL for RMI or disabled it. 您已为RMI设置SSL或将其禁用。 官网地址 http://jmeter.apache.org/usermanual/jmeter_distributed_testing_step_by_step.html 压测注意事项：一定要用内网IP，不用用公网IP]]></content>
      <categories>
        <category>软件测试</category>
      </categories>
      <tags>
        <tag>测试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【软件测试】负载测试、压力测试的区别]]></title>
    <url>%2F2019%2F01%2F14%2F%E3%80%90%E8%BD%AF%E4%BB%B6%E6%B5%8B%E8%AF%95%E3%80%91%E8%B4%9F%E8%BD%BD%E6%B5%8B%E8%AF%95%E3%80%81%E5%8E%8B%E5%8A%9B%E6%B5%8B%E8%AF%95%E7%9A%84%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[性能测试分为两种，负载测试和压力测试 负载测试的目标是测试在一定负载情况下的系统性能，实际过程中，通常先较小的负载开始，逐渐增加请求的数量和用户数量，观察不同负载下系统的响应时间、所消耗的资源，直到系统响应超时，这里的负荷必须是工作负荷。 压力测试是指在一定的负载压力下，系统长时间运行的稳定性。]]></content>
      <categories>
        <category>软件测试</category>
      </categories>
      <tags>
        <tag>测试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python中的__init__.py文件和导包总结]]></title>
    <url>%2F2019%2F01%2F14%2Fpython%E4%B8%AD%E7%9A%84-init-py%E6%96%87%E4%BB%B6%E5%92%8C%E5%AF%BC%E5%8C%85%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[python __init__.py文件和导包总结import也是一门学问～ 导入方式 importfrom xxx import yyy __init__.py的作用 把某一个目录变成一个包，使得其他模块使用 包.包中的某一模块/函数/变量/类 这种方式时可用 __init__.py什么时候有用？ 如果某一个目录在后期导入使用时只是作为中间目录衔接使用，则可以不加__init__.py， 如果某个目录后期会被直接或间接显示地作为一个包导入并被使用，那么必须必须必须要加__init__.py，并且__init__.py中的内容会影响导入的内容 每一个目录都是可以被import的 如果一个目录下没有__init__.py，那么在import这个目录时，并不会报错，只会以这个目录名创建一个namespace，里面什么都没有，没有使用价值 module ‘name’ (namespace) 然而当目录下创建__init__.py后这个目录就可以成为一个包 module ‘name’ from ‘/Users/miechongdaxia/测试/test/name/__init__.py‘ 在pycharm下都以绝对路径来引用包或者模块 不要用 . 操作符，尤其是用from import这种方式，import一般直接导入外层目录作为包，而from import会导入内层目录中的包或者模块 python查找模块/包的路径 sys.path的值就是路径 哪些东西可以被直接import？ 模块文件（.py文件） C或C++扩展（已编译为共享库或DLL文件） 目录/包（包含多个模块，不一定要有__init__.py，具体差别看第四点） 内建模块（使用C编写并已链接到Python解释器中） 两种导入方式的区别 from import 可以导入模块中的函数/变量/类等import则不行，导入的不是模块就是包目录，无法细化到函数/变量/类等 如果一个目录需要作为一个包使用，一定要在目录下创建__init__.py，并且在里面写好可以导入的模块，不然包目录可以导入，但是无法使用！！！！！]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python变量与变量作用域]]></title>
    <url>%2F2019%2F01%2F14%2Fpython%E5%8F%98%E9%87%8F%E4%B8%8E%E5%8F%98%E9%87%8F%E4%BD%9C%E7%94%A8%E5%9F%9F%2F</url>
    <content type="text"><![CDATA[c语言中，变量的定义会为变量分配一块内存，变量的内存地址不会发生改变，当变量的值发生改变时，改变的是对应内存地址中的值。 python中，给变量赋值时，变量保存的是一个对象的引用，如果想改变变量的值，其实改变的是变量保存的引用，使变量指向了另一个对象。 在函数中执行赋值操作时，会创建一个局部变量，如果想在函数中通过赋值‘=’改变一个全局变量，则需要用关键字global申明，只要出现了‘=’操作符，则这个变量就是局部变量，除非显示申明为global。 LEGB，在某一作用域内想使用某个变量时，会按照LEGB的顺序来查找，找不到则会报错。 给函数传参，函数的形参是一个局部变量，这个局部变量和传入的实参都绑定在某一对象上，函数运行完后，将这个局部变量会被解绑。 函数return后，接收的变量会绑定在return的对象上，return结束后会把原函数内绑定在这个对象上的变量解绑。]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python中几个高阶函数的使用]]></title>
    <url>%2F2019%2F01%2F14%2Fpython%E4%B8%AD%E5%87%A0%E4%B8%AA%E9%AB%98%E9%98%B6%E5%87%BD%E6%95%B0%E7%9A%84%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[Higher-Order functions mapmap函数接收一个函数和一个列表,列表中的每个元素会依次传入函数,就像映射一样 &gt;&gt;&gt;print(list(map(lambda x:x**2,[1,2,3]))) &gt;&gt;&gt;[1,4,9] filter过滤函数,也接收一个函数和一个列表,列表中的值会依次传入函数中,返回值是True的会保留 同花顺的一道笔试题: 用lambda函数求1-100中能被21整除的数. -------------------------------------- &gt;&gt;&gt;list(filter(lambda x:x%21==0,range(1,101))) &gt;&gt;&gt;[21,42,63,84] reducereduce也接收一个函数和一个列表,不同的是这个函数需要接收2个参数,刚开始列表的前两个元素传入函数,得到一个返回值,这个返回值和列表中的下一个元素再一次传入函数,再得到返回值,一直到列表中的元素用完为止 &gt;&gt;&gt;from functools import reduce &gt;&gt;&gt;reduce(lambda x,y:x*y,range(1,6)) &gt;&gt;&gt;120 虽然这几个函数很简单,但用的好的话会使程序简单些,这些小技巧需要慢慢积累,python带来的便利需用起来]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法导论——第十三章、红黑树算法实现]]></title>
    <url>%2F2019%2F01%2F14%2F%E7%AE%97%E6%B3%95%E5%AF%BC%E8%AE%BA%E2%80%94%E2%80%94%E7%AC%AC%E5%8D%81%E4%B8%89%E7%AB%A0%E3%80%81%E7%BA%A2%E9%BB%91%E6%A0%91%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[class TreeNode: def __init__(self, value, color=None): self.value = value self.parent = None self.left = None self.right = None self.color = color class RBT: def __init__(self): self.sentry = TreeNode(value=&apos;sentry&apos;, color=&apos;black&apos;) self.root = self.sentry def maximum(self, node): while node.right is not self.sentry: node = node.right return node def minimum(self, node): while node.left is not self.sentry: node = node.left return node def search(self, node, val): while node is not None and val != node.value: if val &lt; node.value: node = node.left else: node = node.right return node def travel(self, node): if self.root is not None: if node.value != &apos;sentry&apos;: print(&apos;value:&apos;, node.value, &apos;parent:&apos;, node.parent.value, &apos;color:&apos;, node.color) if node.left is not None: self.travel(node.left) if node.right is not None: self.travel(node.right) def left_rotate(self, node): t = node.right node.right = t.left if t.left is not self.sentry: t.left.parent = node t.parent = node.parent if node.parent is self.sentry: self.root = t elif node == node.parent.left: node.parent.left = t elif node == node.parent.right: node.parent.right = t t.left = node node.parent = t def right_totate(self, node): t = node.left node.left = t.right if t.right is not self.sentry: t.right.parent = node t.parent = node.parent if node.parent is self.sentry: self.root = t elif node == node.parent.left: node.parent.left = t elif node == node.parent.right: node.parent.right = t t.right = node node.parent = t def insert(self, node): s = self.sentry p = self.root while p is not self.sentry: s = p if node.value &lt; p.value: p = p.left elif node.value &gt;= p.value: p = p.right node.parent = s if s is self.sentry: self.root = node elif node.value &lt; s.value: s.left = node elif node.value &gt;= s.value: s.right = node node.left = self.sentry node.right = self.sentry node.color = &apos;red&apos; self.insert_fixup(node) def insert_fixup(self, node): while node.parent.color == &apos;red&apos;: if node.parent is node.parent.parent.left: uncle = node.parent.parent.right if uncle.color == &apos;red&apos;: node.parent.color = &apos;black&apos; uncle.color = &apos;black&apos; node.parent.parent.color = &apos;red&apos; node = node.parent.parent else: if node is node.parent.right: node = node.parent self.left_rotate(node) node.parent.color = &apos;black&apos; node.parent.parent.color = &apos;red&apos; self.right_totate(node.parent.parent) elif node.parent is node.parent.parent.right: uncle = node.parent.parent.left if uncle and uncle.color == &apos;red&apos;: node.parent.color = &apos;black&apos; uncle.color = &apos;black&apos; node.parent.parent.color = &apos;red&apos; node = node.parent.parent else: if node is node.parent.left: node = node.parent self.right_totate(node) node.parent.color = &apos;black&apos; node.parent.parent.color = &apos;red&apos; self.left_rotate(node.parent.parent) self.root.color = &apos;black&apos; def exchange_subtree(self, a, b): if a.parent is self.sentry: self.root = b elif a is a.parent.left: a.parent.left = b elif a is a.parent.right: a.parent.right = b b.parent = a.parent def delete(self, node): t = node node_old_color = t.color if node.left is self.sentry: x = node.right self.exchange_subtree(node, node.right) elif node.right is self.sentry: x = node.left self.exchange_subtree(node, node.left) else: t = self.minimum(node.right) node_old_color = node.color x = t.right if t.parent is node: x.parent = t else: self.exchange_subtree(t, t.right) t.right = node.right t.right.parent = t self.exchange_subtree(node, t) t.left = node.left t.left.parent = t t.color = node.color if node_old_color == &apos;black&apos;: self.delete_fixup(x) def delete_fixup(self, node): while node is not self.root and node.color == &apos;black&apos;: if node is node.parent.left: t = node.parent.right if t.color == &apos;red&apos;: t.color = &apos;black&apos; node.parent.color = &apos;red&apos; self.left_rotate(node.parent) t = node.parent.right if t.left.color == &apos;black&apos; and t.right.color == &apos;black&apos;: t.color = &apos;red&apos; node = node.parent else: if t.right.color == &apos;black&apos;: t.left.color = &apos;black&apos; t.color = &apos;red&apos; self.right_totate(t) t = node.parent.right t.color = node.parent.color node.parent.color = &apos;black&apos; t.right.color = &apos;black&apos; self.left_rotate(node.parent) node = self.root else: t = node.parent.left if t.color == &apos;red&apos;: t.color = &apos;black&apos; node.parent.color = &apos;red&apos; self.right_totate(node.parent) t = node.parent.left if t.right.color == &apos;black&apos; and t.left.color == &apos;black&apos;: t.color = &apos;red&apos; node = node.parent else: if t.left.color == &apos;black&apos;: t.right.color = &apos;black&apos; t.color = &apos;red&apos; self.left_rotate(t) t = node.parent.left t.color = node.parent.color node.parent.color = &apos;black&apos; t.left.color = &apos;black&apos; self.right_totate(node.parent) node = self.root node.color = &apos;black&apos;]]></content>
      <categories>
        <category>algorithm</category>
      </categories>
      <tags>
        <tag>algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法导论——第十二章、二叉搜索树算法实现]]></title>
    <url>%2F2019%2F01%2F14%2F%E7%AE%97%E6%B3%95%E5%AF%BC%E8%AE%BA%E2%80%94%E2%80%94%E7%AC%AC%E5%8D%81%E4%BA%8C%E7%AB%A0%E3%80%81%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[class TreeNode: def __init__(self, value): self.value = value self.parent = None self.left = None self.right = None class Tree: def __init__(self): self.root = None self.nums = 0 class BST(Tree): def left(self, i): return 2 * i def right(self, i): return 2 * i + 1 def travel(self, node): if self.root is not None: print(node.value) if node.left is not None: self.travel(node.left) if node.right is not None: self.travel(node.right) def insert(self, node): t = None p = self.root while p is not None: t = p if node.value &lt; p.value: p = p.left else: p = p.right node.parent = t if t is None: self.root = node elif node.value &lt; t.value: t.left = node elif node.value &gt;= t.value: t.right = node self.nums += 1 def search(self, node, val): while node is not None and val != node.value: if val &lt; node.value: node = node.left else: node = node.right return node def minimum(self, node): while node.left is not None: node = node.left return node def maximum(self, node): while node.right is not None: node = node.right return node def exchange_subtree(self, a, b): if a.parent is None: self.root = b elif a == a.parent.left: a.parent.left = b elif a == a.parent.right: a.parent.right = b if b is not None: b.parent = a.parent def delete(self, node): if node.left is None: self.exchange_subtree(node, node.right) elif node.right is None: self.exchange_subtree(node, node.left) else: min = self.minimum() if min.parent != node: self.exchange_subtree(min, min.right) min.right = node.right min.right.parent = node.parent self.exchange_subtree(node, min) min.left = node.left min.parent = node.parent def reverse(self, node): if node is None: return self.root node.left, node.right = node.right, node.left self.reverse(node.left) self.reverse(node.right) def depth(self, node): if node is None: return 0 l = self.depth(node.left) r = self.depth(node.right) return max(l, r) + 1 def leafnums(self, node): if node is None: return 0 elif node.left is None and node.right is None: return 1 return self.leafnums(node.left) + self.leafnums(node.right) def kth_nodes(self, node, k): if self.root is None: return 0 if k == 0: return 1 return self.kth_nodes(node.left, k - 1) + self.kth_nodes(node.right, k - 1)]]></content>
      <categories>
        <category>algorithm</category>
      </categories>
      <tags>
        <tag>algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法导论——第十章、链表算法实现]]></title>
    <url>%2F2019%2F01%2F14%2F%E7%AE%97%E6%B3%95%E5%AF%BC%E8%AE%BA%E2%80%94%E2%80%94%E7%AC%AC%E5%8D%81%E7%AB%A0%E3%80%81%E9%93%BE%E8%A1%A8%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[class LinkList: def __init__(self): self.head = None self.nums = 0 def __getitem__(self, item): p = self.head if item == 0: return self.head.value elif item &lt; 0: return self.__getitem__(self.nums + item) elif item &gt; self.nums: raise ValueError else: for i in range(item): p = p.next return p.value def is_empty(self): return self.head is None def travel(self): p = self.head if self.is_empty(): raise ValueError while p is not None: print(p.value) p = p.next def get(self, index): p = self.head if self.nums == 0: return self.head.value elif self.is_empty(): raise LinkListEmptyError for i in range(index - 1): p = p.next return p.value def insert(self, node, index=None): p = self.head if self.is_empty(): self.head = node elif index is None or index &gt;= self.nums: while p.next is not None: p = p.next p.next = node else: for i in range(1, index): p = p.next node.next = p.next p.next = node self.nums += 1 def delete(self, index=None): p = self.head if self.is_empty(): raise LinkListEmptyError elif self.nums == 1: self.head = None elif (index is None or index &gt;= self.nums) and self.nums &gt;= 3: while p.next.next is not None: p = p.next p.next = None else: for i in range(1, index): p = p.next p.next = p.next.next self.nums -= 1 def update(self, value, index): p = self.head for i in range(1, index): p = p.next p.value = value def reverse(self): p = None while self.head is not None: q = self.head self.head = q.next q.next = p p = q self.head = p def _exchange(self, i, j): p = self.head q = self.head for m in range(i): p = p.next for n in range(j): q = q.next p.value, q.value = q.value, p.value def quick_sort(self, p, r): if p &lt; r: q = self.partition(p, r) self.quick_sort(p, q - 1) self.quick_sort(q + 1, r) def partition(self, p, r): x = self[r] i = p - 1 for j in range(p, r): if self[j] &lt;= x: i += 1 self._exchange(i, j) self._exchange(i + 1, r) return i + 1]]></content>
      <categories>
        <category>algorithm</category>
      </categories>
      <tags>
        <tag>algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法导论——第十章、栈，队列算法实现]]></title>
    <url>%2F2019%2F01%2F14%2F%E7%AE%97%E6%B3%95%E5%AF%BC%E8%AE%BA%E2%80%94%E2%80%94%E7%AC%AC%E5%8D%81%E7%AB%A0%E3%80%81%E6%A0%88%EF%BC%8C%E9%98%9F%E5%88%97%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[栈 class StackNode: def __init__(self, value): self.value = value self.next = None class Stack: def __init__(self): self.top = None self.nums = 0 def is_empty(self): return self.nums == 0 def push(self, node): if self.top == None: self.top = node else: node.next = self.top self.top = node self.nums += 1 def pop(self): if self.nums == 1: t = self.top self.nums -= 1 self.top = None return t elif self.is_empty(): return None else: t = self.top self.top = self.top.next self.nums -= 1 return t 队列 class QueueNode: def __init__(self, value): self.value = value self.next = None class Queue: def __init__(self): self.top = None self.nums = 0 def is_empty(self): return self.nums == 0 def enqueue(self, node): if self.top is None: self.top = node else: node.next = self.top self.top = node self.nums += 1 def dequeue(self): if self.is_empty(): raise ValueError elif self.nums == 1: t = self.top self.top = None self.nums -= 1 return t p = self.top while p.next.next is not None: p = p.next t = p.next p.next = None self.nums -= 1 return t def peek(self): if self.is_empty(): raise ValueError p = self.top if self.nums == 1: return self.top while p.next is not None: p = p.next return p]]></content>
      <categories>
        <category>algorithm</category>
      </categories>
      <tags>
        <tag>algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法导论——第八章、计数排序，基数排序算法实现]]></title>
    <url>%2F2019%2F01%2F14%2F%E7%AE%97%E6%B3%95%E5%AF%BC%E8%AE%BA%E2%80%94%E2%80%94%E7%AC%AC%E5%85%AB%E7%AB%A0%E3%80%81%E8%AE%A1%E6%95%B0%E6%8E%92%E5%BA%8F%EF%BC%8C%E5%9F%BA%E6%95%B0%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[def counting_sort(input_list, k): &quot;&quot;&quot; :param input_list: list :param k: the largest number of input_list :return: order list &quot;&quot;&quot; c = [0 for _ in range(0, k + 1)] output_list = [0 for _ in range(0, len(input_list))] for j in range(0, len(input_list)): c[input_list[j]] += 1 for j in range(1, k + 1): c[j] += c[j - 1] for j in range(len(input_list) - 1, -1, -1): output_list[c[input_list[j]] - 1] = input_list[j] c[input_list[j]] -= 1 return output_list def radix_sort(lists, radix=10): k = len(list(str(max(lists)))) bucket = [[] for _ in range(radix)] for i in range(1, k + 1): for j in lists: if len(str(j)) &lt; i: bucket[0].append(j) else: bucket[int(str(j)[-i])].append(j) del lists[:] for z in bucket: lists += z del z[:] return lists]]></content>
      <categories>
        <category>algorithm</category>
      </categories>
      <tags>
        <tag>algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法导论——第七章、快速排序算法实现]]></title>
    <url>%2F2019%2F01%2F14%2F%E7%AE%97%E6%B3%95%E5%AF%BC%E8%AE%BA%E2%80%94%E2%80%94%E7%AC%AC%E4%B8%83%E7%AB%A0%E3%80%81%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[def quick_sort(list, p, r): if p &lt; r: q = partition(list, p, r) quick_sort(list, p, q - 1) quick_sort(list, q + 1, r) def partition(list, p, r): x = list[r] i = p - 1 for j in range(p, r): if list[j] &lt;= x: i += 1 list[i], list[j] = list[j], list[i] list[i + 1], list[r] = list[r], list[i + 1] return i + 1 def randomized_partition(list, p, r): i = random.randint(p, r) list[i], list[r] = list[r], list[i] return partition(list, p, r) def randomized_quick_sort(list, p, r): if p &lt; r: q = randomized_partition(list, p, r) randomized_quick_sort(list, p, q - 1) randomized_quick_sort(list, q + 1, r)]]></content>
      <categories>
        <category>algorithm</category>
      </categories>
      <tags>
        <tag>algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法导论——第六章、堆排序算法实现]]></title>
    <url>%2F2019%2F01%2F14%2F%E7%AE%97%E6%B3%95%E5%AF%BC%E8%AE%BA%E2%80%94%E2%80%94%E7%AC%AC%E5%85%AD%E7%AB%A0%E3%80%81%E5%A0%86%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[class HEAP: def __init__(self,list): self.list = list self.list.insert(0,None) self.length = len(self.list) - 1 self.heap_size = self.length def _parent(self, i): if i == 1: return 1 else: return i // 2 def _left(self, i): return 2 * i def _right(self, i): return 2 * i + 1 def _max_heapify(self, i): list = self.list l = self._left(i) r = self._right(i) if l &lt;= self.heap_size and list[l] &gt; list[i]: largest = l else: largest = i if r &lt;= self.heap_size and list[r] &gt; list[largest]: largest = r if largest != i: list[i],list[largest] = list[largest],list[i] self._max_heapify(largest) def _build_max_heap(self): for i in range(self.length,0,-1): self._max_heapify(i) def heap_sort(self): self._build_max_heap() for i in range(self.length,1,-1): self.list[1],self.list[i] = self.list[i],self.list[1] self.heap_size -= 1 self._max_heapify(1) return self.list]]></content>
      <categories>
        <category>algorithm</category>
      </categories>
      <tags>
        <tag>algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法导论——第四章、最大子数组，Strassen算法实现]]></title>
    <url>%2F2019%2F01%2F14%2F%E7%AE%97%E6%B3%95%E5%AF%BC%E8%AE%BA%E2%80%94%E2%80%94%E7%AC%AC%E5%9B%9B%E7%AB%A0%E3%80%81%E6%9C%80%E5%A4%A7%E5%AD%90%E6%95%B0%E7%BB%84%EF%BC%8CStrassen%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[#最大子数组 def find_max_crossing_subarray(list, low, high): left_sum = -float(&apos;inf&apos;) right_sum = -float(&apos;inf&apos;) index = ((high + low) // 2) lsum = 0 rsum = 0 if len(list) == 1: return (low, low, list[low]) if len(list) == 2: return (low, high, list[low] + list[high]) for i in range(index, low - 1, -1): lsum += list[i] if lsum &gt; left_sum: left_sum = lsum max_left = i for j in range(index + 1, high + 1): rsum += list[j] if rsum &gt; right_sum: right_sum = rsum max_right = j return (max_left, max_right, left_sum + right_sum) def find_max_subarray(list, low, high): &quot;&quot;&quot; :param list: a list :param low: list lowest index, 0 :param high: high index, len(list)-1 :return: order list &quot;&quot;&quot; if low == high: return (low, high, list[low]) else: mid = (low + high) // 2 (left_low, left_high, left_sum) = find_max_subarray(list, low, mid) (right_low, right_high, right_sum) = find_max_subarray(list, mid + 1, high) (cross_low, cross_high, cross_sum) = find_max_crossing_subarray(list, low, high) if left_sum &gt;= right_sum and left_sum &gt;= cross_sum: return (left_low, left_high, left_sum) elif right_sum &gt;= left_sum and right_sum &gt;= cross_sum: return (right_low, right_high, right_sum) else: return (cross_low, cross_high, cross_sum) #Strassen矩阵乘法 from numpy import array, dot, hstack, vstack def strassen_matrix(a, b): &quot;&quot;&quot; a,b must be n*n matrix, n is 2**p, 2,4,8,16... :param a: :param b: :return: a dot b &quot;&quot;&quot; aa = array(a) bb = array(b) n = aa.shape[0] A11 = [] A12 = [] A21 = [] A22 = [] B11 = [] B12 = [] B21 = [] B22 = [] if n == 1: return a*b if aa.shape[0] &amp; (aa.shape[0] - 1) != 0: return -1 if aa.shape != bb.shape: return -1 if aa.shape[0] != aa.shape[1]: return -1 for i in range(n // 2): A11.append(a[i][0:n // 2]) A12.append(a[i][n // 2:]) B11.append(b[i][0:n // 2]) B12.append(b[i][n // 2:]) for j in range(n // 2, n): A21.append(a[j][0:n // 2]) A22.append(a[j][n // 2:]) B21.append(b[j][0:n // 2]) B22.append(b[j][n // 2:]) A11 = array(A11) A12 = array(A12) A21 = array(A21) A22 = array(A22) B11 = array(B11) B12 = array(B12) B21 = array(B21) B22 = array(B22) S1 = B12 - B22 S2 = A11 + A12 S3 = A21 + A22 S4 = B21 - B11 S5 = A11 + A22 S6 = B11 + B22 S7 = A12 - A22 S8 = B21 + B22 S9 = A11 - A21 S10 = B11 + B12 P1 = strassen_matrix(A11, S1) P2 = strassen_matrix(S2, B22) P3 = strassen_matrix(S3, B11) P4 = strassen_matrix(A22, S4) P5 = strassen_matrix(S5, S6) P6 = strassen_matrix(S7, S8) P7 = strassen_matrix(S9, S10) C11 = P5 + P4 - P2 + P6 C12 = P1 + P2 C21 = P3 + P4 C22 = P5 + P1 - P3 - P7 return (vstack((hstack((C11, C12)), hstack((C21, C22)))))]]></content>
      <categories>
        <category>algorithm</category>
      </categories>
      <tags>
        <tag>algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法导论——第二章、插入排序，归并排序实现]]></title>
    <url>%2F2019%2F01%2F14%2F%E7%AE%97%E6%B3%95%E5%AF%BC%E8%AE%BA%E2%80%94%E2%80%94%E7%AC%AC%E4%BA%8C%E7%AB%A0%E3%80%81%E6%8F%92%E5%85%A5%E6%8E%92%E5%BA%8F%EF%BC%8C%E5%BD%92%E5%B9%B6%E6%8E%92%E5%BA%8F%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[插入排序 def insert_sort(list): for j in range(1, len(list)): key = list[j] i = j - 1 while i &gt;= 0 and list[i] &lt; key: list[i + 1] = list[i] i -= 1 list[i + 1] = key print(list) 归并排序 def merge(list1, list2): L1 = list1 L2 = list2 length = len(list1) + len(list2) L1.append(float(&apos;inf&apos;)) L2.append(float(&apos;inf&apos;)) result = [] m = n = 0 for i in range(length): if L1[m] &lt;= L2[n]: result.append(L1[m]) m += 1 elif L1[m] &gt;= L2[n]: result.append(L2[n]) n += 1 return result def merge_sort(list): if len(list) &lt;= 1: return list q = len(list) // 2 a = merge_sort(list[:q]) b = merge_sort(list[q:]) return merge(a, b)]]></content>
      <categories>
        <category>algorithm</category>
      </categories>
      <tags>
        <tag>algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python标准库--multiprocessing]]></title>
    <url>%2F2019%2F01%2F14%2Fpython%E6%A0%87%E5%87%86%E5%BA%93-multiprocessing%2F</url>
    <content type="text"><![CDATA[基于并行的多进程模块 介绍 multiprocessing模块提供了大量进程接口类似于线程模块，并提供了本地和远程的并发，高效的是用子进程代替了线程，避免了GIL全局解释锁的影响，正因为这样，multiprocessing模块允许程序员充分利用多核处理器，可以在unix和windows上使用。 multiprocessing模块也包括了线程模块不具备的接口，一个只要的例子就是Pool对象，它为一个函数传入多个值从而并发执行提供了方便，因为数据的分配在进程中实现。 Process Class进程大量的产出是通过创建Process对象，然后调用start()方法来实现 from multiprocessing import Process def f(name): print(&apos;hello&apos;, name) if __name__ == &apos;__main__&apos;: p = Process(target=f, args=(&apos;bob&apos;,)) p.start() p.join() Contexts and start methods multiprocessing模块提供了三种开启进程的方式 spawn,fork,forkserver spawn父进程开启一个解释器进程，子进程将只从父进程继承run()时必要的资源，没必要的资源将不会继承，这个开启方法比fork,forkserver慢。在unix和windows上都可用，在windows是默认方法 fork父进程使用os.fork()，fork一个python解释器，子进程进行时和父进程完全相同，所有资源全部继承，fork一个有多个线程的进程会存在问题。只能在unix上可用，并是默认方法 forkserver当使用这种方式启动进程，一个服务器进程会被开启，当需要一个新的进程时，父进程连接服务器并请求fork一个新进程，服务器进程是单线程的，所以它用os.fork()是安全的，不会继承不必要的资源。在支持将文件描述符通过管道传递给unix的系统中可用 _Changed in version 3.4:_spawn在所有unix平台都可用，在windows中子进程不再继承父进程所有资源。通过set_start_method()来设置启动方法，在一个程序中只能设置一次set_start_method(‘spawn’)或者你可以使用get_context()来选择一个上下文对象，和multiprocessing模块有着同样的接口，允许你在同一个程序中使用多个start方法ctx = mp.get_context(‘spawn’)ctx.Process() Exchanging objects between processes 多进程支持进程间两种通信方式 Queue和queue.Queue类似 from multiprocessing import Process, Queue def f(q): q.put([42, None, &apos;hello&apos;]) if __name__ == &apos;__main__&apos;: q = Queue() p = Process(target=f, args=(q,)) p.start() print(q.get()) # prints &quot;[42, None, &apos;hello&apos;]&quot; p.join() 队列是线程和进程安全的，不用自己用锁 PipesPipe()返回一对通过管道连接的对象，默认是全双工的 from multiprocessing import Process, Pipe def f(conn): conn.send([42, None, &apos;hello&apos;]) conn.close() if __name__ == &apos;__main__&apos;: parent_conn, child_conn = Pipe() p = Process(target=f, args=(child_conn,)) p.start() print(parent_conn.recv()) # prints &quot;[42, None, &apos;hello&apos;]&quot; p.join() 每一个连接对象都有send(),recv()方法，如果两个进程或者线程试图同时读取或写入管道的同一端，那么管道中的数据可能会损坏，如果同时读取写入的是管道的不同端则不会有损害的危险。 Synchronization between processes multiprocessing包括了所有类似于线程的同步机制，比如可以使用锁来使得同一时刻只有一个进程输出 from multiprocessing import Process, Lock def f(l, i): l.acquire() try: print(&apos;hello world&apos;, i) finally: l.release() if __name__ == &apos;__main__&apos;: lock = Lock() for num in range(10): Process(target=f, args=(lock, num)).start() Sharing state between processes 在多进程程序中应该避免状态的共享，如果你一定要这么做multiprocessing提供了几种方法 Shared memory数据可以存储在共享内存中，通过Value或者Array映射 from multiprocessing import Process, Value, Array def f(n, a): n.value = 3.1415927 for i in range(len(a)): a[i] = -a[i] if __name__ == &apos;__main__&apos;: num = Value(&apos;d&apos;, 0.0) arr = Array(&apos;i&apos;, range(10)) p = Process(target=f, args=(num, arr)) p.start() p.join() print(num.value) print(arr[:]) output: 3.1415927 [0, -1, -2, -3, -4, -5, -6, -7, -8, -9] ‘d’表示double双精度浮点型，’i’代表int型你可以使用multiprocessing.sharedctypes模块，它支持创建任意类型并分配共享内存。5. Server process通过Manger()创建manger对象，支持的类型有list, dict, Namespace, Lock, RLock, Semaphore, BoundedSemaphore, Condition, Event, Barrier, Queue, Value and Array from multiprocessing import Process, Manager def f(d, l): d[1] = &apos;1&apos; d[&apos;2&apos;] = 2 d[0.25] = None l.reverse() if __name__ == &apos;__main__&apos;: with Manager() as manager: d = manager.dict() l = manager.list(range(10)) p = Process(target=f, args=(d, l)) p.start() p.join() print(d) print(l) output: {0.25: None, 1: &apos;1&apos;, &apos;2&apos;: 2} [9, 8, 7, 6, 5, 4, 3, 2, 1, 0] server process 管理器比内存共享对象更加灵活，因为它支持任意数据类型，一个管理器可以共享给在同一个网络中的进程，但是比共享内存运行要慢。 Using a pool of workers Pool类代表了工作进程池，允许将任务卸载到进程中去 from multiprocessing import Pool, TimeoutError import time import os def f(x): return x*x if __name__ == &apos;__main__&apos;: # start 4 worker processes with Pool(processes=4) as pool: # print &quot;[0, 1, 4,..., 81]&quot; print(pool.map(f, range(10))) # print same numbers in arbitrary order for i in pool.imap_unordered(f, range(10)): print(i) # evaluate &quot;f(20)&quot; asynchronously res = pool.apply_async(f, (20,)) # runs in *only* one process print(res.get(timeout=1)) # prints &quot;400&quot; # evaluate &quot;os.getpid()&quot; asynchronously res = pool.apply_async(os.getpid, ()) # runs in *only* one process print(res.get(timeout=1)) # prints the PID of that process # launching multiple evaluations asynchronously *may* use more processes multiple_results = [pool.apply_async(os.getpid, ()) for i in range(4)] print([res.get(timeout=1) for res in multiple_results]) # make a single worker sleep for 10 secs res = pool.apply_async(time.sleep, (10,)) try: print(res.get(timeout=1)) except TimeoutError: print(&quot;We lacked patience and got a multiprocessing.TimeoutError&quot;) print(&quot;For the moment, the pool remains available for more work&quot;) # exiting the &apos;with&apos;-block has stopped the pool print(&quot;Now the pool is closed and no longer available&quot;) 注意，Pool的方法只应该被创建它的进程所使用。 ReferenceProcess and exceptions class multiprocessing.Process(group=None, target=None, name=None, args=(), kwargs={}, *, daemon=None) run()调用traget传入的方法 start()开启激活进程，每个进程只能开启一次 join([timeout])阻塞直到所有进程都执行完毕或者到达设定的timeout时间试图在进程启动之前加入进程是错误的。 name没有实际意义，多进程间可以使用相同的名字，但不建议这么做 is_alive()返回进程是否是存活状态，当进程调用start()后存活 daemon是否为守护进程，是布尔值，必须在start()前设置，初始值会设定成父进程对应的值当进程退出时，它所有创建的守护进程都将终止守护进程不允许创建子进程 pid返回进程id exitcode返回退出状态码 authkey进程的身份验证密钥(字节字符串)，当multiprocessing被主进程初始化，会被os.urandom()分配一个随机的字符串，当一个进程对象被创建，它将继承父进程的认证密钥，虽然这可以通过设置authkey另一字节串改。 sentinel一个系统对象的数字句柄，当进程结束时，它将变成“ready”状态，你可以使用这个值来等待多个事件完成，multiprocessing.connection.wait()，否则使用join()更简单 terminate()终止进程，进程的后代进程不会终止——它们将成为孤立的进程Warning:如果在关联进程使用管道或队列时使用此方法，则管道或队列容易损坏并可能被其他进程不可用。类似地，如果进程获取了锁或信号量等，则终止它很容易导致其他进程死锁。 start(),join(),is_alive(),terminate(),exitcode只能被进程对象(object)调用 exception multiprocessing.ProcessErrormultiprocessing exceptions 基类 exception multiprocessing.BufferTooShortConnection.recv_bytes_into()，当提供的缓冲区对象太小而无法读取消息时。 exception multiprocessing.AuthenticationError认证错误 exception multiprocessing.TimeoutError超时错误__]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python library</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python标准库--queue]]></title>
    <url>%2F2019%2F01%2F14%2Fpython%E6%A0%87%E5%87%86%E5%BA%93-queue%2F</url>
    <content type="text"><![CDATA[队列模块实现了多消费者、多生产者队列，当数据在多线程之间需要安全交互时非常有用，队列模块实现了所有必要的锁，它依赖于python可靠的线程支持模块实现了三种类型的队列，区别在于检索出条目的顺序。FIFO队列，先进先出；LIFO队列，和栈类似，后进的先出；优先队列，将队列中的元素排序呢，最小的先出。队列模块实现的类和异常：* class queue.Queue(maxsize=0) class queue.LifoQueue(maxsize=0) class queue.PriorityQueue(maxsize=0)注意：当maxsize设置为0或者负数时，队列的大小变为无限，如果队列大小有限，当队列满时，插入会被阻塞 exception queue.Empty队列为空时，如果使用了未阻塞的get()或者是get_nowait()则会引发异常 exception queue.Full队列满时，如果使用了未阻塞的put()或者是put_nowait()也会引发异常 Queue Objects Queue.qsize()返回队列的大致大小，qsize()大于0并不能保证get()不会被阻塞，同样qsize()小于maxsize也不会保证put()不会被阻塞 Queue.empty()返回队列是否为空，为空不能保证put()不会被阻塞，不为空不能保证get()不会被阻塞 Queue.full()返回队列是否已满，如果已经满了不能保证get()不会被阻塞，如果未满也不能保证put()不会被阻塞 Queue.put(item, block=True, timeout=None)将数据放入队列，如果block=True,timeout=None，也就是默认情况下，如果队列已满则会阻塞直到队列有余量，如果timeout为正数，到达timeout指定时间，队列还是满的话会引发full异常如果block设置为false，队列未满则放入数据成功，队列已满会立即引发异常，这种情况下timeout会被忽略 Queue.put_nowait(item)等价于put(item, False) Queue.get(block=True, timeout=None)从队列中移走并返回一个数据，如果block=True,timeout=None，也就是默认情况下，如果队列为空则会阻塞知道队列中有元素可以被取出，如果timeout为正数，到达timeout指定时间，队列还是空的话会引发empty异常，如果block设置为false，队列不为空则返回数据，为空则立即引发异常，这种情况下timeout会被忽略 Queue.get_nowait()等价于get(False) Queue.task_done()申明之前的队列任务已经完成，被用在消费线程中，用get()来获取数据，获取完毕后通过 task_done()告诉队列，任务完毕如果有一个join()当前依旧阻塞，那么它知道队列中所有元素都被取出后才会恢复(即所有队列中元素都被task_done()调用申明已经处理完毕)如果task_done()调用次数大于队列中的元素数量，则会引发ValueError异常 Queue.join()阻塞，知道所有队列中的元素被取出和调用task_done申明处理完毕当有元素加入到队列中时，未完成的任务数会增加，当有元素从队列中取出并且调用task_done()时，未完成任务数会减少，当未完成任务数为0时，join()变成不阻塞状态]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python library</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python标准库--threading]]></title>
    <url>%2F2019%2F01%2F14%2Fpython%E6%A0%87%E5%87%86%E5%BA%93-threading%2F</url>
    <content type="text"><![CDATA[threading.active_count()返回当前存活的线程数 threading.current_thread()返回当前线程对象，如果当前没有线程，则返回一个功能有限的虚拟线程对象dummy thread object threading.get_ident()返回一个非零线程标识符，没有实际意义，作为类似魔数cookie来使用，比如索引一个包含特定线程数据的字典，当一个线程退出后，其标识符可以循环使用 threading.enumerate() 返回当前所有存活的线程列表，包括后台线程，dummy线程和主线程，不包括终止的和未开启的线程 threading.main_thread() 返回主线程，通常是从解释器启动的 threading.settrace(func)为所有线程设置一个跟踪函数，这个函数会传递给sys.settrace()，会正对于每个线程，要在线程run()之前使用 threading.setprofile(func)与settrace类似，为每个线程设置一个配置文件函数 threading.stack_size([size])返回创建新线程时堆栈的大小，可以指定size用于随后创建的线程堆栈大小，size要么是0要么是大于32kb的正整数，所以size最小为32*1024bytes32kb目前支持的最小的堆栈大小值，为解释器本身保证足够的堆栈空间 threading.TIMEOUT_MAX返回获取锁或者等待函数的最大超时时间，超过会返回OverflowError Class threading.local为线程保存特有的数据，threading.local()mydata = threading.local()mydata.x = 1 Thread Objects有两种方法来制定线程的活动，第一种是在创建线程时指定traget，它默认会被run()方法调用，第二种方法是创建一个子类，并重写__init__和run()方法一旦一个线程对象被创建，它必须通过调用线程的start()方法启动，并且会调用run()方法一旦线程的活动启动，线程就被认为是“alive”状态，当run()方法终止时或者接受了一个未处理的异常，线程就会停止alive状态is_alive()方法可以检测线程是否存活 class threading.Thread(group=None, target=None, name=None, args=(), kwargs={}, *, daemon=None)线程的构造函数:参数group是保留的参数，为将来实现线程组的功能，默认为None；参数target是将在函数run()调用的函数，默认为None；参数name是线程名称；参数args是目标调用的函数参数；参数kwargs是目标调用的字典参数，如果显示设置了daemon，则会将线程设置为后台如果子类重写了构造函数，它必须确保调用基类的构造函数(Thread.__init__())在做其他事情之前 start()启动线程，每个线程对象最多必须调用一次，否则会产生RuntimeError run()线程运行的主函数，可以继承线程类重载这个函数，有参数的话需要传参 join(timeout=None)等待线程终止，这会阻塞线程直到终止、产生异常或者超时timeout单位为秒，join总是返回None，如果想知道一个线程是否发生超时，你要在join()后调用is_alive()，如果还存活则超时如果timeout没有被设置，则阻塞到所有线程终止一个线程可以多次调用join()，join会引发RuntimeError，如果试图加入当前线程，并会造成死锁，join会引发相同的错误，如果加入一个未启动的线程 name仅用于识别的字符串，它没有实际意义，多个线程可以被赋予相同的名称，初始名称由构造函数设置 getName()setName(name)老的API，可以直接用name属性代替 ident获取标识 is_alive()线程是否存活，存活的条件是线程已经调用了run()方法，并且还未终止 daemonisDaemon()setDaemon()线程是否为守护线程或者叫后台线程，可直接调用属性，老的API Lock Objects原生锁有两种状态，locked或者unlocked，当它是locked时不由特定的线程拥有有两种方法acquire() 和 release()，当状态是unlocked时，调用acquire()获得锁，状态有unlocked变成locked，当状态是locked时，acquire()会阻塞直到release()，release()只能在locked状态下使用，如果尝试去release()一个unlocked的锁，会引发RunTimeError当多个线程阻塞等待release()时，只有一个线程会获得锁 class threading.Lock acquire(blocking=True, timeout=-1)获取线程锁。当参数blocking设置为True时，直到获取到锁成功才返回；当参数blocking设置为False时，不进行阻塞，调用之后立即返回。如果当设置锁成功，返回True，设置锁不成功返回False；参数timeout是设置阻塞超时间，以秒为单位的小数 release()释放锁，可以从任何线程来释放之前锁住的锁；然后设置锁为无锁状态，允许之前等待之中的一个线程再次获取锁；如果调用此函数之前没有执行任何获取锁的动作，就立即抛出异常RuntimeError不会返回任何值 RLock Objects可重用锁，可以由同一线程多次获取，在内部，它使用了“拥有线程”和“递归级别”的概念，以及原始锁所使用的锁定/解锁状态，在锁定状态下，某些线程拥有锁；在未锁定状态下，没有线程拥有它为了加锁，线程调用acquire()，一旦线程获得了锁就返回，为了解锁，线程调用release()acquire()/release()总是成对出现，release()在最后使用 acquire()同上 release()同上 Condition Objects条件对象，有wait() notify()等方法，主要用来判断线程条件，使其做出正确行为，wait()会释放锁，并且会阻塞线程，直到这个线程被notify()唤醒notify()并不会释放锁，需要用release()释放 消费者-生产者模型很适合这个例子，简述一下：消费者wait()等待某样特定物品，生产者生产许多物品，当生产者生产出特定物品后notify()唤醒消费者达到目的 class threading.Condition(lock=None) acquire(*args) release() wait(timeout=None) wait_for(predicate, timeout=None) notify(n=1) notify_all() Semaphore Objects信号量有一个内部计数器，初始化时会赋予信号量值，这个值不能小于零，当信号量为零时，调用acquire()会阻塞线程，直到release()后信号量不为零 class threading.Semaphore(value=1)，信号量默认值为1，这时和锁差不多 acquire(blocking=True, timeout=None)获取一个信号量 release()释放一个信号量]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python library</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[应用服务器与WSGI协议以及flask后端框架总结(后端接收请求返回响应的整个流程)]]></title>
    <url>%2F2019%2F01%2F14%2F%E5%BA%94%E7%94%A8%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%B8%8EWSGI%E5%8D%8F%E8%AE%AE%E4%BB%A5%E5%8F%8Aflask%E5%90%8E%E7%AB%AF%E6%A1%86%E6%9E%B6%E6%80%BB%E7%BB%93-%E5%90%8E%E7%AB%AF%E6%8E%A5%E6%94%B6%E8%AF%B7%E6%B1%82%E8%BF%94%E5%9B%9E%E5%93%8D%E5%BA%94%E7%9A%84%E6%95%B4%E4%B8%AA%E6%B5%81%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[上次遗留了两个问题,先说一下自己的看法 问题:1.明明一个线程只能处理一个请求,那么栈里的元素永远是在栈顶,那为什么需要用栈这个结构?用普通变量不行吗.2._request_ctx_stack和_app_ctx_stack都是线程隔离的,那么为什么要分开? 我认为在web runtime的情况下是可以不需要栈这个结构的,即使是单线程下也不需要,原本我以为在单线程下,当前一个请求阻塞后,后一个请求还会被推入栈中,结果并不是这样,这也就说明了,栈的结构和是不是单线程没关系,为了验证这点,我写了个简单的接口验证这点: 123456789101112131415161718&gt; from flask import Flask,_request_ctx_stack&gt; &gt; app = Flask(__name__)&gt; &gt; &gt; @app.route(&apos;/&apos;)&gt; def index():&gt; print(_request_ctx_stack._local.__storage__)&gt; time.sleep(1)&gt; return &apos;&lt;h1&gt;hello&lt;/h1&gt;&apos;&gt; &gt; app.run(port=3000)&gt; -------------------------------------------&gt; def wsgi_app(self, environ, start_response):&gt; &gt; ctx = self.request_context(environ)&gt; ctx.push()&gt; print(_request_ctx_stack._local.__storage__) 我在Flask类中的wsgi\_app()方法中加了这一句print(\_request\_ctx\_stack.\_local.\_\_storage__),wsgi_app()是后端接收应用服务器发来的包装好的WSGI请求的函数,后面会讲到,由于一个线程只能处理一个请求,所以结果应该是栈中永远只有一个请求对象,在路由接口中我延时了1秒,假设成阻塞,看一下结果: 1234567891011&gt; * Running on http://127.0.0.1:3000/ (Press CTRL+C to quit)&gt; &#123;139851542578944: &#123;&apos;stack&apos;: []&#125;&#125;&gt; 127.0.0.1 - - [14/Apr/2018 14:31:17] &quot;GET / HTTP/1.1&quot; 200 -&gt; &#123;139851542578944: &#123;&apos;stack&apos;: []&#125;&#125;&gt; 127.0.0.1 - - [14/Apr/2018 14:31:18] &quot;GET / HTTP/1.1&quot; 200 -&gt; &#123;139851542578944: &#123;&apos;stack&apos;: []&#125;&#125;&gt; 127.0.0.1 - - [14/Apr/2018 14:31:19] &quot;GET / HTTP/1.1&quot; 200 -``` &gt; &gt; 每次栈中只有一个请求对象,这也就说明了栈这个结构和web runtime下的单线程无关,那么就剩下非web runtime的情况了,最常见的是离线测试:&gt; from flask import Flask,_request_ctx_stack,_app_ctx_stack app = Flask(__name__) app2 = Flask(__name__) def offline_test(): with app.app_context(): print(_app_ctx_stack._local.__storage__) with app2.app_context(): print(_app_ctx_stack._local.__storage__) with app.app_context(): with app.test_request_context(): print(_request_ctx_stack._local.__storage__) with app.test_request_context(): print(_request_ctx_stack._local.__storage__) 123&gt; &gt; 离线测试是单线程的,通过这个例子也能得到第二的问题的答案,为什么要将请求和应用分开,一个原因是flask支持多个app共存,这需要用到中间件,另一个原因是离线测试时,有可能只需要用到应用上下文,所以需要将两者分开,在离线测试时如果进行了嵌套则栈结构的特点就发挥了出来,看一下运行的结果:&gt; {140402410657536: {&apos;stack&apos;: []}} {140402410657536: {&apos;stack&apos;: [, ]}} {140402410657536: {&apos;stack&apos;: []}} {140402410657536: {&apos;stack&apos;: [, ]}} 123456789101112131415161718&gt; &gt; 结果显而易见 &gt; 总结一下:栈结构和分离请求和应用是为了离线测试更加灵活&gt; &gt; * * *&gt; &gt; 2. web应用服务器 WSGI 后端之间的关系 &gt; web应用服务器的作用是监听端口,当接收到客户端的请求后将请求转化成WSGI格式(environ)然后传给后端框架 &gt; 应用服务器&lt;----WSGI协议----&gt;后端框架 &gt; WSGI是应用服务器和后端框架之间的桥梁,使得服务器和后端框架分离,各司其职,程序员也能专注于自己的逻辑 &gt; 在WSGI中规定了每个python web应用都需要是一个可调用的对象,即实现了\_\_call\_\_这个特殊方法,Flask就是一个可调用对象&gt; &gt; * * *&gt; &gt; 4. web应用服务器从哪里将包装好的请求发送给后端 &gt; 在flask中使用了werkzeug这个工具包,在werkzeug.serving中有一个类,class WSGIRequestHandler(BaseHTTPRequestHandler, object) &gt; 这个类提供了environ字典对象,定义了start\_response()和run\_wsgi()方法,在run_wsgi()中有一个execute(),看一下源码:&gt; def execute(app): application_iter = app(environ, start_response) #从这里发送到后端 try: for data in application_iter: write(data) if not headers_sent: write(b&apos;&apos;) finally: if hasattr(application_iter, &apos;close&apos;): application_iter.close() application_iter = None 1234567891011121314&gt; &gt; 第一句application\_iter = app(environ, start\_response)就调用了Flask.\_\_call\_\_(),并将environ, start\_response传入,而Flask.\_\_call__()就return了self.wsgi_app(), &gt; 这个wsgi\_app(environ, start\_response)是一个标准的请求处理函数,所以它就是整个后端处理请求的入口函数,environ是一个包含所有HTTP请求信息的字典对象,start\_response是一个发送HTTP响应的函数,environ是从应用服务器传过来的,start\_response是定义好的,这些都不需要后端开发人员关心 &gt; 总结一下: &gt; 1.WSGI规定了后端处理函数的格式,即需要接受environ,start_response这两个参数,这两个参数从应用服务器传给后端框架 &gt; 2.python web应用对象需要是可调用的,即实现了\_\_call\_\_方法,返回WSGI规定格式的后端处理函数来处理请求及返回响应 &gt; 3.应用服务器会使用werkzeug.serving中的WSGIRequestHandler类中的相应方法,将http请求转化成WSGI格式,所以说werkzeug是一个遵循WSGI协议的工具包,提供给应用服务器使用 &gt; &gt; &gt; * * *&gt; &gt; 6. 后端处理请求返回响应整个流程 &gt; 之前说到,后端处理请求的入口函数是wsgi\_app(self,environ,start\_response),先看下源码:&gt; def wsgi_app(self, environ, start_response): ctx = self.request_context(environ) #1 ctx.push() #2 error = None try: try: response = self.full_dispatch_request() #3 except Exception as e: error = e response = self.handle_exception(e) except: error = sys.exc_info()[1] raise return response(environ, start_response) finally: if self.should_ignore_error(error): error = None ctx.auto_pop(error) 1234&gt; &gt; 其中有三句比较关键,我写了序号 &gt; 第一句:self.request\_context(environ),看下request\_context这个方法:&gt; def request_context(self, environ): return RequestContext(self, environ) 1234&gt; &gt; 简而言之,传入environ,初始化一个请求上下文对象并返回 &gt; 第二句:ctx.push(),看下源码:&gt; def push(self): top = _request_ctx_stack.top if top is not None and top.preserved: top.pop(top._preserved_exc) app_ctx = _app_ctx_stack.top if app_ctx is None or app_ctx.app != self.app: app_ctx = self.app.app_context() app_ctx.push() self._implicit_app_ctx_stack.append(app_ctx) else: self._implicit_app_ctx_stack.append(None) if hasattr(sys, &apos;exc_clear&apos;): sys.exc_clear() _request_ctx_stack.push(self) self.session = self.app.open_session(self.request) if self.session is None: self.session = self.app.make_null_session() 1234&gt; &gt; 简而言之,推入应用上下文和请求上下文,如果设置了secret_key则开启一个session,关于flask的session放到后面说 &gt; 第三句:self.full\_dispatch\_request(),是处理请求的关键函数,看下源码:&gt; def full_dispatch_request(self): &quot;&quot;&quot;Dispatches the request and on top of that performs request pre and postprocessing as well as HTTP exception catching and error handling. .. versionadded:: 0.7 &quot;&quot;&quot; self.try_trigger_before_first_request_functions() try: request_started.send(self) rv = self.preprocess_request() #function1 if rv is None: rv = self.dispatch_request() #function2 except Exception as e: rv = self.handle_user_exception(e) return self.finalize_request(rv) #function3 123456789101112&gt; &gt; 这个函数中嵌套了另外三个函数,预处理函数preprocess\_request(),主处理函数dispatch\_request()和最终处理函数finalize_request(rv) &gt; 1.preprocess\_request()是处理被before\_request装饰器装饰的函数 &gt; 2.dispatch_request()匹配请求的URL,并返回视图函数的返回值rv &gt; 3.finalize\_request(rv)接受视图函数的返回值,并生成响应,这里有make\_response和process\_response这两个函数,make\_response生成响应对象,process_response对响应做一些处理,比如后面要讲到的session &gt; 响应生成后,在wsgi\_app中return response,最后调用ctx.auto\_pop()将请求和应用上下文推出栈,return的response会通过start_response发送到应用服务器,并由其发送到客户端,这样一次请求就结束了.&gt; &gt; * * *&gt; &gt; 8. 最后说说session &gt; flask中的session是client side session,说白了就是session会封装在cookie中在最终响应时会发送给客户端,而在服务器本地不会存储,所以叫作client side session,要使用session需要设置secret\_key这个配置,通过app.secret\_key来设置,用来验证签名,等到下次客户端发来带有cookie的请求时,后端就能从生成对应的session中解析出带有的信息,写个简单的应用来看下session怎么用:&gt; from flask import Flask,session app = flask.Flask(__name__) app.secret_key = &apos;gjx&apos; @app.route(&apos;/&apos;) def index(): if &apos;name&apos; in session: print(session[&apos;name&apos;]) else: print(&apos;stranger&apos;) return &apos;&lt;h1&gt;/&lt;/h1&gt;&apos; @app.route(&apos;/&apos;) def test(name): session[&apos;name&apos;] = name print(&apos;session set successful&apos;) return &apos;&lt;h1&gt;test&lt;/h1&gt;&apos; app.run(port=3000) 12345678&gt; &gt; 跑起来后,在浏览器输入127.0.0.1:3000/,会打印出stranger, &gt; 然后访问127.0.0.1:3000/jx后,后端打印出session set successful,并且浏览器会收到服务器发来的cookie, &gt; Set-Cookie:session=eyJuYW1lIjoiangifQ.DbNHuQ.MPZLWzoLdga2SPMg0plMYmKlJMc; HttpOnly; Path=/ 这是我测试时收到的,有三个字段,第一个是session的内容,第二个是时间戳,第三个是验证信息 &gt; 这时已经设置好了session,并且得到了cookie,再次访问127.0.0.1:3000/,后端打印出了jx,就是之前设置的值 &gt; 如果对session内的值更改,则返回的cookie也会更改,那么在那保存,在那创建session呢? &gt; 之前在分析后端请求流程是提到了,在RequestContext的push方法最后:&gt; self.session = self.app.open_session(self.request) if self.session is None: self.session = self.app.make_null_session() 1234&gt; &gt; 如果设置了secret\_key则会执行open\_session开启一个session,那如果更改了在哪里保存呢? &gt; 在finalize\_request执行的self.process\_response中:&gt; def process_response(self, response): ctx = _request_ctx_stack.top bp = ctx.request.blueprint funcs = ctx._after_request_functions if bp is not None and bp in self.after_request_funcs: funcs = chain(funcs, reversed(self.after_request_funcs[bp])) if None in self.after_request_funcs: funcs = chain(funcs, reversed(self.after_request_funcs[None])) for handler in funcs: response = handler(response) if not self.session_interface.is_null_session(ctx.session): self.save_session(ctx.session, response) return response ` 在最后判断如果session不是null session的话会执行self.save\_session来保存更新session,在self.save\_session中会调用response.set_cookie,flask中的session大概就是这样 总结一下:1.分析了应用服务器封装好的environ从哪发送给后端2.分析了应用服务器 WSGI 后端之间的关系以及WSGI协议对接口的标准定义,使得后端人员只需要关心自己的逻辑3.分析了后端接收到应用服务器发来的WSGI请求之后的一系列处理流程,主要函数是wsgi_app(environ,start_response)4.最后简单分析了flask中的session机制,它是client side session的.]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>flask</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[flask如何开启多线程详解]]></title>
    <url>%2F2019%2F01%2F14%2Fflask%E5%A6%82%E4%BD%95%E5%BC%80%E5%90%AF%E5%A4%9A%E7%BA%BF%E7%A8%8B%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[flask开启多线程 在我之前写的’flask中current_app、g、request、session源码的深究和理解’一文中解释了flask如何支持多线程主要通过两个类来实现,LocalStack和Local,在Local中有两个属性,__storage__和__ident_func__,后者用来获取线程id,从而区分不同线程发来的请求 这次要说的是flask如何开启多线程 先从app.run()这个方法看起 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193 def run(self, host=None, port=None, debug=None, **options): from werkzeug.serving import run_simple if host is None: host = &apos;127.0.0.1&apos; if port is None: server_name = self.config[&apos;SERVER_NAME&apos;] if server_name and &apos;:&apos; in server_name: port = int(server_name.rsplit(&apos;:&apos;, 1)[1]) else: port = 5000 if debug is not None: self.debug = bool(debug) options.setdefault(&apos;use_reloader&apos;, self.debug) options.setdefault(&apos;use_debugger&apos;, self.debug) try: run_simple(host, port, self, **options) #会进入这个函数 finally: # reset the first request information if the development server # reset normally. This makes it possible to restart the server # without reloader and that stuff from an interactive shell. self._got_first_request = False``` &gt; &gt; 经过判断和设置后进入run_simple()这个函数,看下源码&gt; ``` def run_simple(hostname, port, application, use_reloader=False, use_debugger=False, use_evalex=True, extra_files=None, reloader_interval=1, reloader_type=&apos;auto&apos;, threaded=False, processes=1, request_handler=None, static_files=None, passthrough_errors=False, ssl_context=None): &quot;&quot;&quot;Start a WSGI application. Optional features include a reloader, multithreading and fork support. This function has a command-line interface too:: python -m werkzeug.serving --help .. versionadded:: 0.5 `static_files` was added to simplify serving of static files as well as `passthrough_errors`. .. versionadded:: 0.6 support for SSL was added. .. versionadded:: 0.8 Added support for automatically loading a SSL context from certificate file and private key. .. versionadded:: 0.9 Added command-line interface. .. versionadded:: 0.10 Improved the reloader and added support for changing the backend through the `reloader_type` parameter. See :ref:`reloader` for more information. :param hostname: The host for the application. eg: ``&apos;localhost&apos;`` :param port: The port for the server. eg: ``8080`` :param application: the WSGI application to execute :param use_reloader: should the server automatically restart the python process if modules were changed? :param use_debugger: should the werkzeug debugging system be used? :param use_evalex: should the exception evaluation feature be enabled? :param extra_files: a list of files the reloader should watch additionally to the modules. For example configuration files. :param reloader_interval: the interval for the reloader in seconds. :param reloader_type: the type of reloader to use. The default is auto detection. Valid values are ``&apos;stat&apos;`` and ``&apos;watchdog&apos;``. See :ref:`reloader` for more information. :param threaded: should the process handle each request in a separate thread? :param processes: if greater than 1 then handle each request in a new process up to this maximum number of concurrent processes. :param request_handler: optional parameter that can be used to replace the default one. You can use this to replace it with a different :class:`~BaseHTTPServer.BaseHTTPRequestHandler` subclass. :param static_files: a list or dict of paths for static files. This works exactly like :class:`SharedDataMiddleware`, it&apos;s actually just wrapping the application in that middleware before serving. :param passthrough_errors: set this to `True` to disable the error catching. This means that the server will die on errors but it can be useful to hook debuggers in (pdb etc.) :param ssl_context: an SSL context for the connection. Either an :class:`ssl.SSLContext`, a tuple in the form ``(cert_file, pkey_file)``, the string ``&apos;adhoc&apos;`` if the server should automatically create one, or ``None`` to disable SSL (which is the default). &quot;&quot;&quot; if not isinstance(port, int): raise TypeError(&apos;port must be an integer&apos;) if use_debugger: from werkzeug.debug import DebuggedApplication application = DebuggedApplication(application, use_evalex) if static_files: from werkzeug.wsgi import SharedDataMiddleware application = SharedDataMiddleware(application, static_files) def log_startup(sock): display_hostname = hostname not in (&apos;&apos;, &apos;*&apos;) and hostname or &apos;localhost&apos; if &apos;:&apos; in display_hostname: display_hostname = &apos;[%s]&apos; % display_hostname quit_msg = &apos;(Press CTRL+C to quit)&apos; port = sock.getsockname()[1] _log(&apos;info&apos;, &apos; * Running on %s://%s:%d/ %s&apos;, ssl_context is None and &apos;http&apos; or &apos;https&apos;, display_hostname, port, quit_msg) def inner(): try: fd = int(os.environ[&apos;WERKZEUG_SERVER_FD&apos;]) except (LookupError, ValueError): fd = None srv = make_server(hostname, port, application, threaded, processes, request_handler, passthrough_errors, ssl_context, fd=fd) if fd is None: log_startup(srv.socket) srv.serve_forever() if use_reloader: # If we&apos;re not running already in the subprocess that is the # reloader we want to open up a socket early to make sure the # port is actually available. if os.environ.get(&apos;WERKZEUG_RUN_MAIN&apos;) != &apos;true&apos;: if port == 0 and not can_open_by_fd: raise ValueError(&apos;Cannot bind to a random port with enabled &apos; &apos;reloader if the Python interpreter does &apos; &apos;not support socket opening by fd.&apos;) # Create and destroy a socket so that any exceptions are # raised before we spawn a separate Python interpreter and # lose this ability. address_family = select_ip_version(hostname, port) s = socket.socket(address_family, socket.SOCK_STREAM) s.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1) s.bind(get_sockaddr(hostname, port, address_family)) if hasattr(s, &apos;set_inheritable&apos;): s.set_inheritable(True) # If we can open the socket by file descriptor, then we can just # reuse this one and our socket will survive the restarts. if can_open_by_fd: os.environ[&apos;WERKZEUG_SERVER_FD&apos;] = str(s.fileno()) s.listen(LISTEN_QUEUE) log_startup(s) else: s.close() # Do not use relative imports, otherwise &quot;python -m werkzeug.serving&quot; # breaks. from werkzeug._reloader import run_with_reloader run_with_reloader(inner, extra_files, reloader_interval, reloader_type) else: inner() #默认会执行 还是经过一系列判断后默认会进入inner()函数,这个函数定义在run\_simple()内,属于闭包,inner()中会执行make\_server()这个函数,看下源码: def make_server(host=None, port=None, app=None, threaded=False, processes=1, request_handler=None, passthrough_errors=False, ssl_context=None, fd=None): &quot;&quot;&quot;Create a new server instance that is either threaded, or forks or just processes one request after another. &quot;&quot;&quot; if threaded and processes &gt; 1: raise ValueError(&quot;cannot have a multithreaded and &quot; &quot;multi process server.&quot;) elif threaded: return ThreadedWSGIServer(host, port, app, request_handler, passthrough_errors, ssl_context, fd=fd) elif processes &gt; 1: return ForkingWSGIServer(host, port, app, processes, request_handler, passthrough_errors, ssl_context, fd=fd) else: return BaseWSGIServer(host, port, app, request_handler, passthrough_errors, ssl_context, fd=fd) 看到这也很明白了,想要配置多线程或者多进程,则需要设置threaded或processes这两个参数,而这两个参数是从app.run()中传递过来的: app.run(**options) ---&gt; run\_simple(threaded,processes) ---&gt; make\_server(threaded,processes) 默认情况下flask是单线程,单进程的,想要开启只需要在run中传入对应的参数:app.run(threaded=True)即可. 从make_server中可知,flask提供了三种server:ThreadedWSGIServer,ForkingWSGIServer,BaseWSGIServer,默认情况下是BaseWSGIServer 以线程为例,看下ThreadedWSGIServer这个类: 123456789101112131415161718192021222324252627282930313233343536class ThreadedWSGIServer(ThreadingMixIn, BaseWSGIServer): #继承自ThreadingMixIn, BaseWSGIServer &quot;&quot;&quot;A WSGI server that does threading.&quot;&quot;&quot; multithread = True daemon_threads = True ThreadingMixIn = socketserver.ThreadingMixInclass ThreadingMixIn: &quot;&quot;&quot;Mix-in class to handle each request in a new thread.&quot;&quot;&quot; # Decides how threads will act upon termination of the # main process daemon_threads = False def process_request_thread(self, request, client_address): &quot;&quot;&quot;Same as in BaseServer but as a thread. In addition, exception handling is done here. &quot;&quot;&quot; try: self.finish_request(request, client_address) self.shutdown_request(request) except: self.handle_error(request, client_address) self.shutdown_request(request) def process_request(self, request, client_address): &quot;&quot;&quot;Start a new thread to process the request.&quot;&quot;&quot; t = threading.Thread(target = self.process_request_thread, args = (request, client_address)) t.daemon = self.daemon_threads t.start() process_request就是对每个请求产生一个新的线程来处理最后写一个非常简单的应用来验证以上说法: 1234567891011121314from flask import Flaskfrom flask import _request_ctx_stackapp = Flask(__name__)@app.route(&apos;/&apos;)def index(): print(_request_ctx_stack._local.__ident_func__()) while True: pass return &apos;&lt;h1&gt;hello&lt;/h1&gt;&apos;app.run() #如果需要开启多线程则app.run(threaded=True) _request_ctx_stack._local.__ident_func__()对应这get_ident()这个函数,返回当前线程id,为什么要在后面加上while True这句呢,我们看下get_ident()这个函数的说明: Return a non-zero integer that uniquely identifies the current thread amongst other threads that exist simultaneously. This may be used to identify per-thread resources. Even though on some platforms threads identities may appear to be allocated consecutive numbers starting at 1, this behavior should not be relied upon, and the number should be seen purely as a magic cookie. A thread’s identity may be reused for another thread after it exits. 关键字我已经加粗了,线程id会在线程结束后重复利用,所以我在路由函数中加了这个死循环来阻塞请求以便于观察到不同的id,这就会产生两种情况:1.没开启多线程的情况下,一次请求过来,服务器直接阻塞,并且之后的其他请求也都阻塞2.开启多线程情况下,每次都会打印出不同的线程id 结果: --------------------- 第一种情况 &gt;&gt;&gt; * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit) &gt;&gt;&gt;139623180527360 --------------------- 第二种情况 &gt;&gt;&gt; * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit) &gt;&gt;&gt;140315469436672 &gt;&gt;&gt;140315477829376 &gt;&gt;&gt;140315486222080 &gt;&gt;&gt;140315316901632 &gt;&gt;&gt;140315105163008 &gt;&gt;&gt;140315096770304 &gt;&gt;&gt;140315088377600 结果显而易见综上所述:flask支持多线程,但默认没开启,其次app.run()只适用于开发环境,生产环境下可以使用uWSGI,Gunicorn等web服务器]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>flask</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[flask中current_app、g、request、session源码的深究和理解]]></title>
    <url>%2F2019%2F01%2F14%2Fflask%E4%B8%ADcurrent-app%E3%80%81g%E3%80%81request%E3%80%81session%E6%BA%90%E7%A0%81%E7%9A%84%E6%B7%B1%E7%A9%B6%E5%92%8C%E7%90%86%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[本文是我在学习flask中对上下文和几个类似全局变量的思考和研究，也有我自己的理解在内。 为了研究flask中的current_app、g、request、session，我找到定义在global.py的源码：1234567`# context locals_request_ctx_stack = LocalStack()_app_ctx_stack = LocalStack()current_app = LocalProxy(_find_app)request = LocalProxy(partial(_lookup_req_object, &apos;request&apos;))session = LocalProxy(partial(_lookup_req_object, &apos;session&apos;))g = LocalProxy(partial(_lookup_app_object, &apos;g&apos;))` 可以看到主要由_lookup_req_object、_lookup_app_object、_find_app等组成，我先来分析request和session其实request和session原理上是一样的，所以将其归为一类，称为请求上下文。 我们从最里面看起，partial(_lookup_req_object, ‘request’)，最外层是一个偏函数，不过这不是重点，它主要是将’request’传给_lookup_req_object，没有其他含义， 顺着_lookup_req_object找到它的源码12345678 `def _lookup_req_object(name): top = _request_ctx_stack.top if top is None: raise RuntimeError(_request_ctx_err_msg) return getattr(top, name)` ``` &gt; &gt; 从最后的return可以看到，这个函数的主要功能是从top中取出键值为&apos;request&apos;的内容，top是一个字典，top从\_request\_ctx\_stack.top中来，在上面的源码中 \_request\_ctx\_stack = LocalStack()，从名字来看LocalStack应该是一个栈类，应该有pop,push,top方法，我继续找到源码： ``def __init__(self): self._local = Local() ... ... def push(self, obj): &quot;&quot;&quot;Pushes a new item to the stack&quot;&quot;&quot; rv = getattr(self._local, &apos;stack&apos;, None) if rv is None: self._local.stack = rv = [] rv.append(obj) return rv def pop(self): &quot;&quot;&quot;Removes the topmost item from the stack, will return the old value or `None` if the stack was already empty. &quot;&quot;&quot; stack = getattr(self._local, &apos;stack&apos;, None) if stack is None: return None elif len(stack) == 1: release_local(self._local) return stack[-1] else: return stack.pop() @property def top(self): &quot;&quot;&quot;The topmost item on the stack. If the stack is empty, `None` is returned. &quot;&quot;&quot; try: return self._local.stack[-1] except (AttributeError, IndexError): return None`` 12&gt; &gt; 可以看到LocalStack()这个类有一个属性self._local = Local()，对应另一个类，继续看源码： ` def __init__(self): object.__setattr__(self, &apos;__storage__&apos;, {}) object.__setattr__(self, &apos;__ident_func__&apos;, get_ident) ... ... def __getattr__(self, name): try: return self.__storage__[self.__ident_func__()][name] except KeyError: raise AttributeError(name) def __setattr__(self, name, value): ident = self.__ident_func__() storage = self.__storage__ try: storage[ident][name] = value except KeyError: storage[ident] = {name: value} ` 12&gt; &gt; 我截取了几个重要的函数，LocalStack()中的push，用到了Local()中的\_\_setattr\_\_();pop用到了\_\_getattr\_\_()，看到push和pop都是对&apos;stack&apos;这个键值进行查询和赋值，我们转到Local()这个类中，这个类有两个实例属性，\_\_storage\_\_和\_\_ident\_func__，前者是一个字典，后者是一个函数，我们看一下这个get_ident函数，查看源码： `def get_ident(): # real signature unknown; restored from __doc__ &quot;&quot;&quot; get_ident() -&gt; integer Return a non-zero integer that uniquely identifies the current thread amongst other threads that exist simultaneously. This may be used to identify per-thread resources. Even though on some platforms threads identities may appear to be allocated consecutive numbers starting at 1, this behavior should not be relied upon, and the number should be seen purely as a magic cookie. A thread&apos;s identity may be reused for another thread after it exits. &quot;&quot;&quot; return 0` ` 显然这个函数不是python写的，因为它来自_thread.py，是一个底层库，从名字可以猜到和线程有关，根据描述，它返回一个非零整数，代表了当前线程id，我们再看看__setattr__这个方法，它其实是一个字典嵌套列表再嵌套字典的数据，__storage__是一个字典，它里面的键值被赋值为当前线程id，这个键值对应的值是另一个字典:{‘stack’:[‘request’:r_val,’session’:s_val]}，这样和前面联系起来就很好理解了，Local()中的__storage__存储的格式为{thread_id:{‘stack’:[‘request’:r_val,’session’:s_val]}}，LocalStack()中的top方法，返回了’stack’中最后一个加入的元素，也就是最新的元素，我自己理解为服务器接受的最新的请求，在框架外看起来request和session是一个全局变量，其实内部已经由进程id将其分隔开了，即使同时有多个请求过来，进程间的数据也不会混乱。 同理current_app和g也一样，唯一不同的是，current_app、g和request、session是两个不同的实例，注意前面 _request_ctx_stack = LocalStack()、_app_ctx_stack = LocalStack()，所以’stack’中存的数据也不一样，current_app和g称为应用上下文，两者还是有区别的。LocalProxy 则是一个典型的代理模式实现，它在构造时接受一个 callable 的参数（比如一个函数），这个参数被调用后的返回值本身应该是一个 Thread Local 对象。对一个 LocalProxy 对象的所有操作，包括属性访问、方法调用（当然方法调用就是属性访问）甚至是二元操作，都会转发到那个 callable 参数返回的 Thread Local 对象上。LocalProxy 的一个使用场景是 LocalStack 的 __call__ 方法。比如 my_local_stack 是一个 LocalStack 实例，那么 my_local_stack() 能返回一个 LocalProxy 对象，这个对象始终指向 my_local_stack 的栈顶元素。如果栈顶元素不存在，访问这个 LocalProxy 的时候会抛出 RuntimeError。需要注意的是，如果需要离线编程，尤其在写测试代码时，需要将应用上下文push到栈中去，不然current_app会指向空的_app_ctx_stack栈顶，自然也就无法工作了。我们可以通过current_app的值来判断是否进入应用上下文中，可以用app.app_context().push()来进入应用上下文。]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>flask</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[从app.route装饰器引发对endpoint的思考]]></title>
    <url>%2F2019%2F01%2F14%2F%E4%BB%8Eapp-route%E8%A3%85%E9%A5%B0%E5%99%A8%E5%BC%95%E5%8F%91%E5%AF%B9endpoint%E7%9A%84%E6%80%9D%E8%80%83%2F</url>
    <content type="text"><![CDATA[还是先来看看源码 1234567891011121314151617181920212223242526272829def route(self, rule, **options): &quot;&quot;&quot;A decorator that is used to register a view function for a given URL rule. This does the same thing as :meth:`add_url_rule` but is intended for decorator usage:: @app.route(&apos;/&apos;) def index(): return &apos;Hello World&apos; For more information refer to :ref:`url-route-registrations`. :param rule: the URL rule as string :param endpoint: the endpoint for the registered URL rule. Flask itself assumes the name of the view function as endpoint :param options: the options to be forwarded to the underlying :class:`~werkzeug.routing.Rule` object. A change to Werkzeug is handling of method options. methods is a list of methods this rule should be limited to (``GET``, ``POST`` etc.). By default a rule just listens for ``GET`` (and implicitly ``HEAD``). Starting with Flask 0.6, ``OPTIONS`` is implicitly added and handled by the standard request handling. &quot;&quot;&quot; def decorator(f): endpoint = options.pop(&apos;endpoint&apos;, None) self.add_url_rule(rule, endpoint, f, **options) return f return decorator route传入了**options这样一个字典，一般我们会传方法methods进去，GET、POST，如果不自己设置endpoint=….的话默认就是No。然后进入add_url_rule函数看一看： 123456789101112131415def add_url_rule(self, rule, endpoint=None, view_func=None, **options): if endpoint is None: endpoint = _endpoint_from_view_func(view_func) options[&apos;endpoint&apos;] = endpoint methods = options.pop(&apos;methods&apos;, None)......... self.url_map.add(rule) if view_func is not None: old_func = self.view_functions.get(endpoint) if old_func is not None and old_func != view_func: raise AssertionError(&apos;View function mapping is overwriting an &apos; &apos;existing endpoint function: %s&apos; % endpoint) self.view_functions[endpoint] = view_func 这里我截取了一些重点的，可以看到如果endpoint为None，会调用_endpoint_from_view_func函数来给endpoint赋值，看一下_endpoint_from_view_func的代码： 1234567def _endpoint_from_view_func(view_func): &quot;&quot;&quot;Internal helper that returns the default endpoint for a given function. This always is the function name. &quot;&quot;&quot; assert view_func is not None, &apos;expected view func if endpoint &apos; \ &apos;is not provided.&apos; return view_func.__name__ 可以看到将视图函数名赋值给了endpoint，所以如果我们创建视图函数时不在**options中指明endpoint的话，默认就是视图函数名，后半部分进行了判断，保证了endpoint的唯一，并将view_func保存在view_functions这个字典中，并且和endpoint形成映射关系，还将路径加入到当前应用中， 这样做的好处是，当我们用url_for()从一个endpoint来找到一个URL时，可以顺着这个映射关系来找，而不用写URL， 常见的用法是url_for(blueprint.endpoint,parm=val…)进行重定向，这样可以获取一个视图函数的路径，传给redirect()，redirect(location,code=302)函数会把接收的参数作为响应body中的Location字段返回给客户端，并且默认是302临时重定向。 123456def redirect(location, code=302, Response=None):...... #为Location字段赋值，返回给客户端进行重定向 response.headers[&apos;Location&apos;] = location return response 总结： URL&lt;————&gt;endpoint&lt;————&gt;view 一个视图函数的endpoint如果不设置那么就是视图函数名。 为URL和view搭起桥梁，使得整个后端框架更加灵活。 url_for(.endpoint)返回的是视图函数对应的URL，URL是对应视图函数装饰器传入的值。]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>flask</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[flask接收请求并推入栈]]></title>
    <url>%2F2019%2F01%2F13%2Fflask%E6%8E%A5%E6%94%B6%E8%AF%B7%E6%B1%82%E5%B9%B6%E6%8E%A8%E5%85%A5%E6%A0%88%2F</url>
    <content type="text"><![CDATA[flask接收请求并推入栈前面两篇讲明了flask怎么支持多线程以及怎么开启多线程的,这篇来讲讲当后端接收到请求后是怎么一步步封装的 1.Flask类中的wsgi_app() 当应用启动后WSGI Server会通过Flask.call()接收http请求,Flask.call()中返回的是wsgi_app()方法, 123456789101112131415161718 def wsgi_app(self, environ, start_response): ctx = self.request_context(environ) ctx.push() error = None try: try: response = self.full_dispatch_request() except Exception as e: error = e response = self.handle_exception(e) except: error = sys.exc_info()[1] raise return response(environ, start_response) finally: if self.should_ignore_error(error): error = None ctx.auto_pop(error) wsgi_app()主要做了两件事情: 第一件事是通过Flask的另一个方法request_context()返回得到了一个封装好的RequsetContext对象,ctx = self.request_context(environ),然后调用RequestContext中的push(),12345678910111213141516171819class RequestContext(object): def push(self): app_ctx = _app_ctx_stack.top if app_ctx is None or app_ctx.app != self.app: app_ctx = self.app.app_context() app_ctx.push() self._implicit_app_ctx_stack.append(app_ctx) else: self._implicit_app_ctx_stack.append(None) if hasattr(sys, &apos;exc_clear&apos;): sys.exc_clear() _request_ctx_stack.push(self) self.session = self.app.open_session(self.request) if self.session is None: self.session = self.app.make_null_session() 在最后调用了_request_ctx_stack.push(self),将请求对象推入请求上下文栈中第二件事是在RequestContext的push()中调用app_ctx = self.app.app_context(),app_ctx.push(),将app推入应用上下文栈,深究下去时可以发现,在RequestContext中有个app属性,它在Flask中的request_context(),也就是在wasi_app()中调用self.request_context(environ)时被赋值, 12def request_context(self, environ): return RequestContext(self, environ) 可以看到每次都传入了self,也就是Flask对象,它在RequestContext中赋值给了self.app,所以在RequestContext push()中每次推入应用上下文的app都是同一个 有两点需要注意: 1.在web runtime情况下,请求上下文和应用上下文,同时存在,同时消亡 2.创建完应用后不会立即生成应用上下文 2.RequestContext中放了request和sessionAppContext中放了gcurrent_app就是AppContext对象 3.Local()中的storage这个字典格式是{thread_id:{‘stack’:[,…]}}所以LocalStack中的top方法返回的结果有两个:一个是RequestContext对象,一个是AppContext对象 最后抛两个问题,下次写1.明明一个线程只能处理一个请求,那么栈里的元素永远是在栈顶,那为什么需要用栈这个结构?用普通变量不行吗.2._request_ctx_stack和_app_ctx_stack都是线程隔离的,那么为什么要分开?]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>flask</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[迁移原EasyThink的博文]]></title>
    <url>%2F2019%2F01%2F13%2F%E8%BF%81%E7%A7%BB%E5%8E%9FEasyThink%E7%9A%84%E5%8D%9A%E6%96%87%2F</url>
    <content type="text"><![CDATA[迁移原EasyThink的博文 原EasyThink的网站为easythink.herokuapp.com， 在2018年2月建站，从今天2019年1月13日开始将原来的博文迁移到github.io上， 今后写博文将在此网站上更新，域名easythink.top将在博文全部迁移完后指向github.io。]]></content>
      <tags>
        <tag>杂记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[flask_login模块中user_loader装饰器引发的思考]]></title>
    <url>%2F2019%2F01%2F13%2Fflask-login%E6%A8%A1%E5%9D%97%E4%B8%ADuser-loader%E8%A3%85%E9%A5%B0%E5%99%A8%E5%BC%95%E5%8F%91%E7%9A%84%E6%80%9D%E8%80%83%2F</url>
    <content type="text"><![CDATA[flask_login模块中user_loader装饰器引发的思考今天看书遇到了flask login模块中的信号机制，看到user_loader这个装饰器时有些疑惑，为什么需要这个装饰器呢，先看一下源码： 12345678910def user_loader(self, callback): &apos;&apos;&apos; This sets the callback for reloading a user from the session. The function you set should take a user ID (a ``unicode``) and return a user object, or ``None`` if the user does not exist. :param callback: The callback for retrieving a user object. :type callback: callable &apos;&apos;&apos; self.user_callback = callback return callback 看到这不禁疑惑，它的作用只是将被它包装的函数存到self.user_callback这个属性中去，我们先到login_user这个登陆函数中去看看： 12345678910111213141516171819202122232425 def login_user(user, remember=False, duration=None, force=False, fresh=True): if not force and not user.is_active: return False user_id = getattr(user, current_app.login_manager.id_attribute)() session[&apos;user_id&apos;] = user_id session[&apos;_fresh&apos;] = fresh session[&apos;_id&apos;] = current_app.login_manager._session_identifier_generator() if remember: session[&apos;remember&apos;] = &apos;set&apos; if duration is not None: try: # equal to timedelta.total_seconds() but works with Python 2.6 session[&apos;remember_seconds&apos;] = (duration.microseconds + (duration.seconds + duration.days * 24 * 3600) * 10**6) / 10.0**6 except AttributeError: raise Exception(&apos;duration must be a datetime.timedelta, &apos; &apos;instead got: &#123;0&#125;&apos;.format(duration)) _request_ctx_stack.top.user = user user_logged_in.send(current_app._get_current_object(), user=_get_user()) return True 可以看到，login_user这个函数接受user这个主要的参数，getattr(user, current_app.login_manager.id_attribute)()这句是为了调用user中的get_id方法123self.id_attribute = ID_ATTRIBUTEID_ATTRIBUTE = &apos;get_id&apos; 注意在getattr后面还有个()所以会调用对应的方法，所以user_id中就存放了登陆用户的id号，并写入到session中去，如果设置了remember为True的话，关掉浏览器重新打开后，用户不会退出，函数的最后_request_ctx_stack.top.user = user，将当前user加入到请求上下文的栈顶，就能用current_user获取了。上面说到self.user_callback已经存了被user_loader装饰的函数，那么在哪里用到了它呢，我在login_manager.py中查找，发现只有一个方法使用到了这个熟悉，这个方法是reload_user()：123456789101112131415161718192021222324252627282930313233343536 def reload_user(self, user=None): &apos;&apos;&apos; This set the ctx.user with the user object loaded by your customized user_loader callback function, which should retrieved the user object with the user_id got from session. Syntax example: from flask_login import LoginManager @login_manager.user_loader def any_valid_func_name(user_id): # get your user object using the given user_id, # if you use SQLAlchemy, for example: user_obj = User.query.get(int(user_id)) return user_obj Reason to let YOU define this self.user_callback: Because we won&apos;t know how/where you will load you user object. &apos;&apos;&apos; ctx = _request_ctx_stack.top if user is None: user_id = session.get(&apos;user_id&apos;) if user_id is None: ctx.user = self.anonymous_user() else: if self.user_callback is None: raise Exception( &quot;No user_loader has been installed for this &quot; &quot;LoginManager. Refer to&quot; &quot;https://flask-login.readthedocs.io/&quot; &quot;en/latest/#how-it-works for more info.&quot;) user = self.user_callback(user_id) if user is None: ctx.user = self.anonymous_user() else: ctx.user = user else: ctx.user = user 它先从请求上下文中取出最新的请求，如果没有传入user，那么会从session中试图取出对应的user_id，这是一种保护机制，不使用cookie，而使用session，user_id在login时会写入session，如果登陆时remember参数传入了True，那么关闭浏览器重新打开后session[‘user_id’]将不会被清除，这时候也就可以获取到了，如果登陆时没有设置remember为True，那么关闭浏览器后user_id会被设为None，则ctx.user = self.anonymous_user()，栈顶的用户为匿名用户，也就需要重新登陆了;取出了user_id，并且self.user_callback不为空，则会调用被user_loader装饰的函数，并传入user_id，在被装饰的函数中我们要根据这个user_id来查找并返回对应的用户实例，如果成功返回，那么当前请求上下文栈顶的用户就设置为返回的用户。你可能会问，为什么要重载用户呢？因为http协议是无状态的，每次都会发送一个新的请求，请求上下文的栈顶会被新的请求覆盖，对应的user属性也就没了，所以需要通过reload_user重载上一次记录在session中并且未被清除的用户，重载失败则需要重新登陆，这也就是这个装饰器的作用了。最后我们看下logout_user()这个方法：123456789101112131415161718192021222324def logout_user(): &apos;&apos;&apos; Logs a user out. (You do not need to pass the actual user.) This will also clean up the remember me cookie if it exists. &apos;&apos;&apos; user = _get_user() if &apos;user_id&apos; in session: session.pop(&apos;user_id&apos;) if &apos;_fresh&apos; in session: session.pop(&apos;_fresh&apos;) cookie_name = current_app.config.get(&apos;REMEMBER_COOKIE_NAME&apos;, COOKIE_NAME) if cookie_name in request.cookies: session[&apos;remember&apos;] = &apos;clear&apos; if &apos;remember_seconds&apos; in session: session.pop(&apos;remember_seconds&apos;) user_logged_out.send(current_app._get_current_object(), user=user) current_app.login_manager.reload_user() return True logout主要是清除了session和cookie中的关键参数，比如login时设置的user_id以及remember等，清除后又调用了reload_user()，根据之前的逻辑，当然不可能重载成功，因为user_id已经为None了，执行到ctx.user = self.anonymous_user()就已经结束了，其实reload_user算是这个模块中很关键的一个函数，login_manager这个类也是这个模块的核心所在，以后有时间继续研究。]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>flask</tag>
        <tag>web</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[flask-login中的login_required装饰器]]></title>
    <url>%2F2019%2F01%2F13%2Fflask-login%E4%B8%AD%E7%9A%84login-required%E8%A3%85%E9%A5%B0%E5%99%A8%2F</url>
    <content type="text"><![CDATA[flask-login中的login_required装饰器123456789101112131415161718192021def login_required(func): @wraps(func) def decorated_view(*args, **kwargs): if request.method in EXEMPT_METHODS: return func(*args, **kwargs) elif current_app.login_manager._login_disabled: return func(*args, **kwargs) elif not current_user.is_authenticated: return current_app.login_manager.unauthorized() return func(*args, **kwargs) return decorated_view 总结 EXEMPT_METHODS参数为EXEMPT_METHODS = set([‘OPTIONS’])，current_app.login_manager._login_disabled 默认是False，在login_manager.py第119行，self._login_disabled = app.config.get(‘LOGIN_DISABLED’, False)，如果没有设置的话，默认是False，一般会进行到第三句判断，current_user.is_authenticated，判断当前用户是否认证，如果没有认证的话就执行unauthorized()，unauthorized()会重定向到login_view参数设置的路由函数中去，所以在实例化LoginManager后要设置login_view属性，当用户没有登陆时，会自动重定向到登陆界面，没有设置会返回401错误， 用户登陆后，这个装饰器就直接返回func(*args, **kwargs)，相当于没有包装一样，装饰器起到包装接口的作用。]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>flask</tag>
        <tag>web</tag>
      </tags>
  </entry>
</search>
